{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd project for the bloc 1 of the Jedha certification of data science & engineering.\n",
    "Author : Youenn Patat\n",
    "\n",
    "![Kayak](https://seekvectorlogo.com/wp-content/uploads/2018/01/kayak-vector-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of cities than we will focus ourselves:\n",
    "```python \n",
    "[\"Mont Saint Michel\",\n",
    "\"St Malo\",\n",
    "\"Bayeux\",\n",
    "\"Le Havre\",\n",
    "\"Rouen\",\n",
    "\"Paris\",\n",
    "\"Amiens\",\n",
    "\"Lille\",\n",
    "\"Strasbourg\",\n",
    "\"Chateau du Haut Koenigsbourg\",\n",
    "\"Colmar\",\n",
    "\"Eguisheim\",\n",
    "\"Besancon\",\n",
    "\"Dijon\",\n",
    "\"Annecy\",\n",
    "\"Grenoble\",\n",
    "\"Lyon\",\n",
    "\"Gorges du Verdon\",\n",
    "\"Bormes les Mimosas\",\n",
    "\"Cassis\",\n",
    "\"Marseille\",\n",
    "\"Aix en Provence\",\n",
    "\"Avignon\",\n",
    "\"Uzes\",\n",
    "\"Nimes\",\n",
    "\"Aigues Mortes\",\n",
    "\"Saintes Maries de la mer\",\n",
    "\"Collioure\",\n",
    "\"Carcassonne\",\n",
    "\"Ariege\",\n",
    "\"Toulouse\",\n",
    "\"Montauban\",\n",
    "\"Biarritz\",\n",
    "\"Bayonne\",\n",
    "\"La Rochelle\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Get the weather and localisation with API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two different APIs used: \n",
    "*   https://nominatim.org/ to get the gps coordinates of all the cities (no subscription required) Documentation : https://nominatim.org/release-docs/develop/api/Search/\n",
    "\n",
    "*   https://openweathermap.org/appid (you have to subscribe to get a free apikey) and https://openweathermap.org/api/one-call-api to get some information about the weather for the 35 cities and put it in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1rst test with just the Mont Saint Michel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://nominatim.openstreetmap.org/search?q=\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "r = requests.get(url+\"Mont+Saint+Michel&format=json\", headers=headers)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place_id': 263784127,\n",
       " 'licence': 'Data ¬© OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n",
       " 'osm_type': 'way',\n",
       " 'osm_id': 211285890,\n",
       " 'lat': '48.6359541',\n",
       " 'lon': '-1.511459954959514',\n",
       " 'class': 'tourism',\n",
       " 'type': 'attraction',\n",
       " 'place_rank': 30,\n",
       " 'importance': 0.4723710249003365,\n",
       " 'addresstype': 'tourism',\n",
       " 'name': 'Mont Saint-Michel',\n",
       " 'display_name': \"Mont Saint-Michel, Grande Terrasse de l'Ouest, Le Mont-Saint-Michel, Avranches, Manche, Normandie, France m√©tropolitaine, 50170, France\",\n",
       " 'boundingbox': ['48.6349172', '48.6370310', '-1.5133292', '-1.5094796']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': '48.6359541', 'lon': '-1.511459954959514', 'name': 'Mont Saint-Michel'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = {key: value for key, value in r.json()[0].items() if 'lat' in key or 'lon' in key or 'name' in key}\n",
    "del coordinates['display_name']\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works !!! We obtained the `json` of informations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lat', 'lon', 'name'])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lat, lon, name]\n",
       "Index: []"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = coordinates.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will loop with all the city names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"St+Malo\", \"Bayeux\", \"Le+Havre\", \"Rouen\", \"Paris\", \"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau+du+Haut+Koenigsbourg\", \"Colmar\",\n",
    "\"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges+du+Verdon\", \"Bormes+les+Mimosas\", \"Cassis\", \"Marseille\", \"Aix+en+Provence\",\n",
    "\"Avignon\", \"Uzes\", \"Nimes\", \"Aigues+Mortes\", \"Saintes+Maries+de+la+mer\", \"Collioure\", \"Carcassonne\", \"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\",\n",
    "\"Bayonne\", \"La+Rochelle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 city done <Response [200]>\n",
      "2 city done <Response [200]>\n",
      "3 city done <Response [200]>\n",
      "4 city done <Response [200]>\n",
      "5 city done <Response [200]>\n",
      "6 city done <Response [200]>\n",
      "7 city done <Response [200]>\n",
      "8 city done <Response [200]>\n",
      "9 city done <Response [200]>\n",
      "10 city done <Response [200]>\n",
      "11 city done <Response [200]>\n",
      "12 city done <Response [200]>\n",
      "13 city done <Response [200]>\n",
      "14 city done <Response [200]>\n",
      "15 city done <Response [200]>\n",
      "16 city done <Response [200]>\n",
      "17 city done <Response [200]>\n",
      "18 city done <Response [200]>\n",
      "19 city done <Response [200]>\n",
      "20 city done <Response [200]>\n",
      "21 city done <Response [200]>\n",
      "22 city done <Response [200]>\n",
      "23 city done <Response [200]>\n",
      "24 city done <Response [200]>\n",
      "25 city done <Response [200]>\n",
      "26 city done <Response [200]>\n",
      "27 city done <Response [200]>\n",
      "28 city done <Response [200]>\n",
      "29 city done <Response [200]>\n",
      "30 city done <Response [200]>\n",
      "31 city done <Response [200]>\n",
      "32 city done <Response [200]>\n",
      "33 city done <Response [200]>\n",
      "34 city done <Response [200]>\n",
      "35 city done <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://nominatim.openstreetmap.org/search?q=\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "for i in range(len(cities_list)):\n",
    "    r = requests.get(url+cities_list[i]+\"&format=json\", headers=headers)\n",
    "    print(\"{} city done\".format(i+1), r)\n",
    "    coordinates = {key: value for key, value in r.json()[0].items() if key in ['lat', 'lon', 'name']}\n",
    "    df.loc[i] = coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.6359541</td>\n",
       "      <td>-1.511459954959514</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.0260409</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.2764624</td>\n",
       "      <td>-0.7024738</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.4938975</td>\n",
       "      <td>0.1079732</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.4404591</td>\n",
       "      <td>1.0939658</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude           Longitude               Name\n",
       "0  48.6359541  -1.511459954959514  Mont Saint-Michel\n",
       "1   48.649518          -2.0260409         Saint-Malo\n",
       "2  49.2764624          -0.7024738             Bayeux\n",
       "3  49.4938975           0.1079732           Le Havre\n",
       "4  49.4404591           1.0939658              Rouen"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'lat':'Latitude', 'lon':'Longitude', 'name':'Name'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cities_localisation.csv\", index=False, encoding=\"utf-8\")\n",
    "df.to_json(\"city_localisation.json\", orient=\"records\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude               Name\n",
       "0  48.635954  -1.511460  Mont Saint-Michel\n",
       "1  48.649518  -2.026041         Saint-Malo\n",
       "2  49.276462  -0.702474             Bayeux\n",
       "3  49.493898   0.107973           Le Havre\n",
       "4  49.440459   1.093966              Rouen"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude               Name\n",
       "0  48.635954  -1.511460  Mont Saint-Michel\n",
       "1  48.649518  -2.026041         Saint-Malo\n",
       "2  49.276462  -0.702474             Bayeux\n",
       "3  49.493898   0.107973           Le Havre\n",
       "4  49.440459   1.093966              Rouen"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_json(\"city_localisation.json\")\n",
    "display(df2.head())\n",
    "\n",
    "df3 = pd.read_csv(\"cities_localisation.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the informations about meteo with the second API.\n",
    "\n",
    "Beginning with a test with one city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "weather_api_key = os.environ.get('WEATHER_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://api.openweathermap.org/data/2.5/weather?q=London,uk&APPID=b63df840e68ed1fabade0a250d87401b\n",
    "lat = df3['Latitude'][0]\n",
    "lon = df3['Longitude'][0]\n",
    "\n",
    "#url = \"https://api.openweathermap.org/data/2.5/weather?lat={}&lon={}&appid={}\".format(lat, lon, weather_api_key) #for current daily weather\n",
    "url = \"https://api.openweathermap.org/data/2.5/forecast?lat={}&lon={}&appid={}&units=metric\".format(lat, lon, weather_api_key) #for 5 days forecast\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "r = requests.get(url, headers=headers)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dt': 1738486800,\n",
       "  'main': {'temp': 1.62,\n",
       "   'feels_like': -2.05,\n",
       "   'temp_min': 1.62,\n",
       "   'temp_max': 1.62,\n",
       "   'pressure': 1021,\n",
       "   'sea_level': 1021,\n",
       "   'grnd_level': 1016,\n",
       "   'humidity': 83,\n",
       "   'temp_kf': 0},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 5},\n",
       "  'wind': {'speed': 3.65, 'deg': 149, 'gust': 7.53},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 09:00:00'},\n",
       " {'dt': 1738497600,\n",
       "  'main': {'temp': 3.2,\n",
       "   'feels_like': -0.05,\n",
       "   'temp_min': 3.2,\n",
       "   'temp_max': 6.35,\n",
       "   'pressure': 1021,\n",
       "   'sea_level': 1021,\n",
       "   'grnd_level': 1017,\n",
       "   'humidity': 77,\n",
       "   'temp_kf': -3.15},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 5},\n",
       "  'wind': {'speed': 3.53, 'deg': 169, 'gust': 4.71},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 12:00:00'},\n",
       " {'dt': 1738508400,\n",
       "  'main': {'temp': 5.79,\n",
       "   'feels_like': 4.02,\n",
       "   'temp_min': 5.79,\n",
       "   'temp_max': 7.87,\n",
       "   'pressure': 1022,\n",
       "   'sea_level': 1022,\n",
       "   'grnd_level': 1017,\n",
       "   'humidity': 69,\n",
       "   'temp_kf': -2.08},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 2},\n",
       "  'wind': {'speed': 2.28, 'deg': 185, 'gust': 3.03},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 15:00:00'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['list'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Clouds\n",
      "1    Clouds\n",
      "2     Clear\n",
      "3     Clear\n",
      "4     Clear\n",
      "dtype: object\n",
      "Average weather will be: Clear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    81\n",
       "1    85\n",
       "2    90\n",
       "3    90\n",
       "4    89\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    4.98\n",
       "1    3.80\n",
       "2    2.16\n",
       "3    0.95\n",
       "4    0.09\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean humidity: 87.0 ; mean temperature: 2.396\n"
     ]
    }
   ],
   "source": [
    "meteo_forecaste = []\n",
    "for i in range(len(r.json())):\n",
    "    meteo_forecaste.append(r.json()['list'][i]['weather'][0]['main'])\n",
    "\n",
    "meteo_forecaste = pd.Series(meteo_forecaste)\n",
    "print(meteo_forecaste)\n",
    "mean_meteo = meteo_forecaste.value_counts().idxmax()\n",
    "print('Average weather will be:', mean_meteo)\n",
    "\n",
    "humidity_forecaste = []\n",
    "temp_forecaste = []\n",
    "for i in range(len(r.json())):\n",
    "    humidity_forecaste.append(r.json()['list'][i]['main']['humidity'])\n",
    "    temp_forecaste.append(r.json()['list'][i]['main']['temp'])\n",
    "\n",
    "humidity_forecaste = pd.Series(humidity_forecaste)\n",
    "temp_forecaste = pd.Series(temp_forecaste)\n",
    "display(humidity_forecaste)\n",
    "display(temp_forecaste)\n",
    "\n",
    "mean_humidity = humidity_forecaste.mean()\n",
    "mean_temp = temp_forecaste.mean()\n",
    "\n",
    "print('mean humidity:', mean_humidity, '; mean temperature:', mean_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we saw that we can have mean humidity, mean temperature and average weather for the forecaste of 5 days for one location. So we will loop this to obtain all these informations for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, Weather, Humidity, Temperature]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janz√©</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City Weather  Humidity  Temperature\n",
       "0  Janz√©   Cloud      4.25           18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_weather = pd.DataFrame( columns = [\"City\", \"Weather\", \"Humidity\", \"Temperature\"])\n",
    "display(df_weather)\n",
    "\n",
    "value1 = 'Janz√©'\n",
    "value2 = 'Cloud'\n",
    "value3 = 4.25\n",
    "value4 =18\n",
    "\n",
    "df_weather.loc[0] = [value1, value2, value3, value4]\n",
    "\n",
    "display(df_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 city weather informations collected <Response [200]>\n",
      "2 city weather informations collected <Response [200]>\n",
      "3 city weather informations collected <Response [200]>\n",
      "4 city weather informations collected <Response [200]>\n",
      "5 city weather informations collected <Response [200]>\n",
      "6 city weather informations collected <Response [200]>\n",
      "7 city weather informations collected <Response [200]>\n",
      "8 city weather informations collected <Response [200]>\n",
      "9 city weather informations collected <Response [200]>\n",
      "10 city weather informations collected <Response [200]>\n",
      "11 city weather informations collected <Response [200]>\n",
      "12 city weather informations collected <Response [200]>\n",
      "13 city weather informations collected <Response [200]>\n",
      "14 city weather informations collected <Response [200]>\n",
      "15 city weather informations collected <Response [200]>\n",
      "16 city weather informations collected <Response [200]>\n",
      "17 city weather informations collected <Response [200]>\n",
      "18 city weather informations collected <Response [200]>\n",
      "19 city weather informations collected <Response [200]>\n",
      "20 city weather informations collected <Response [200]>\n",
      "21 city weather informations collected <Response [200]>\n",
      "22 city weather informations collected <Response [200]>\n",
      "23 city weather informations collected <Response [200]>\n",
      "24 city weather informations collected <Response [200]>\n",
      "25 city weather informations collected <Response [200]>\n",
      "26 city weather informations collected <Response [200]>\n",
      "27 city weather informations collected <Response [200]>\n",
      "28 city weather informations collected <Response [200]>\n",
      "29 city weather informations collected <Response [200]>\n",
      "30 city weather informations collected <Response [200]>\n",
      "31 city weather informations collected <Response [200]>\n",
      "32 city weather informations collected <Response [200]>\n",
      "33 city weather informations collected <Response [200]>\n",
      "34 city weather informations collected <Response [200]>\n",
      "35 city weather informations collected <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "df_cities = pd.read_csv(\"cities_localisation.csv\")\n",
    "\n",
    "df_weather = pd.DataFrame( columns = [\"City\", \"Weather\", \"Humidity\", \"Temperature\"])\n",
    "\n",
    "for i in range(len(cities_list)):\n",
    "    lat = df_cities['Latitude'][i]\n",
    "    lon = df_cities['Longitude'][i]\n",
    "\n",
    "    url = \"https://api.openweathermap.org/data/2.5/forecast?lat={}&lon={}&appid={}&units=metric\".format(lat, lon, weather_api_key) #for 5 days forecast\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "\n",
    "    meteo_forecaste = []\n",
    "    for weather_description in range(len(r.json())):\n",
    "        meteo_forecaste.append(r.json()['list'][weather_description]['weather'][0]['main'])\n",
    "\n",
    "    meteo_forecaste = pd.Series(meteo_forecaste)\n",
    "    mean_meteo = meteo_forecaste.value_counts().idxmax()\n",
    "\n",
    "    humidity_forecaste = []\n",
    "    temp_forecaste = []\n",
    "    for hum_temp in range(len(r.json())):\n",
    "        humidity_forecaste.append(r.json()['list'][hum_temp]['main']['humidity'])\n",
    "        temp_forecaste.append(r.json()['list'][hum_temp]['main']['temp'])\n",
    "\n",
    "    humidity_forecaste = pd.Series(humidity_forecaste)\n",
    "    temp_forecaste = pd.Series(temp_forecaste)\n",
    "    \n",
    "\n",
    "    mean_humidity = humidity_forecaste.mean()\n",
    "    mean_temp = temp_forecaste.mean()\n",
    "\n",
    "    df_weather.loc[i] = [df_cities['Name'][i], mean_meteo, mean_humidity, mean_temp]\n",
    "\n",
    "    print(\"{} city weather informations collected\".format(i+1), r)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_csv(\"cities_weather.csv\", index=False, encoding=\"utf-8\")\n",
    "df_weather.to_json(\"city_weather.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_2 = pd.read_json(\"city_weather.json\")\n",
    "display(df_weather_2.head())\n",
    "\n",
    "df_weather_3 = pd.read_csv(\"cities_weather.csv\")\n",
    "df_weather_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we completed this part and obtained a csv and json file with the city's name associated to the mean weather, humidity and temperature for the next 5 days.  \n",
    "‚ö†Ô∏è It was done the 1srt of February, so the meteo data is not very good for any place in France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Get the hotels infos with the web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web scraping will be done on Booking https://www.booking.com/index.fr.html\n",
    "\n",
    "Informations to scrape:\n",
    "*   hotel name,\n",
    "*   Url to its booking.com page,\n",
    "*   Its coordinates: latitude and longitude\n",
    "*   Score given by the website users\n",
    "*   Text description of the hotel\n",
    "*   Address\n",
    "*   Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will do the testing phase for scraping. When it will be done we will loop it in a spider file (.py file) and store all the data in json files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st step : loop for each city the scraping to get the url page for each hotel. Collect all in multiples json files, 1 per city.  \n",
    "\n",
    "2nd step : loop for each page to get the infos for the hotels, and collect all the data in a json file for each city.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector query=None data='<html><head><script type=\"text/javasc...'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "#url for test for hotels at Mont Saint Michel\n",
    "#https://www.booking.com/searchresults.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ss=Le+Mont-Saint-Michel%C+France&efdco=1&lang=fr&src=index&dest_id=900039327&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=d4b23b24d4940325&checkin=2025-02-02&checkout=2025-02-09&group_adults=2&no_rooms=1&group_children=0&nflt=ht_id%3D204\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "url = \"https://www.booking.com/searchresults.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ss=Le+Mont-Saint-Michel%C+France&efdco=1&lang=fr&src=index&dest_id=900039327&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=d4b23b24d4940325&checkin=2025-02-02&checkout=2025-02-09&group_adults=2&no_rooms=1&group_children=0&nflt=ht_id%3D204\"\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "response = Selector(text=r.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_url = response.css(\"a[class='a78ca197d0']\").attrib[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.booking.com/hotel/fr/hotel-saint-aubert.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-02-02&checkout=2025-02-09&dest_id=900039327&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=916b42ff1a7605b5&srepoch=1738488703&all_sr_blocks=23081103_347524575_0_2_0&highlighted_blocks=23081103_347524575_0_2_0&matching_block_id=23081103_347524575_0_2_0&sr_pri_blocks=23081103_347524575_0_2_0__93120&from=searchresults'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works üëç!\n",
    "\n",
    "Now see for the 2nd step with hotel info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector query=None data='<html><head><script type=\"text/javasc...'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "url = hotel_url\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "response = Selector(text=r.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_name = response.css(\"h2[class='d2fee87262 pp-header__title']::text\").get()\n",
    "url_hotel = url\n",
    "hotel_coordinates = response.css(\"a[id='map_trigger_header']::attr(data-atlas-latlng)\").get()\n",
    "score = response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.')\n",
    "text_description = response.css(\"p[class='a53cbfa6de b3efd73f69']::text\").get()\n",
    "address = response.css(\"div[class='a53cbfa6de f17adf7576']::text\").get()\n",
    "price_week = response.css(\"span[class='prco-valign-middle-helper']::text\").get().replace(\"\\xa0\", \"\").replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le Saint Aubert'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.booking.com/hotel/fr/hotel-saint-aubert.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-02-02&checkout=2025-02-09&dest_id=900039327&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=916b42ff1a7605b5&srepoch=1738488703&all_sr_blocks=23081103_347524575_0_2_0&highlighted_blocks=23081103_347524575_0_2_0&matching_block_id=23081103_347524575_0_2_0&sr_pri_blocks=23081103_347524575_0_2_0__93120&from=searchresults'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48.612937834706464,-1.5101051330566406'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.7'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nich√© dans un √©crin de verdure, √† seulement 2 km du Mont-Saint-Michel, Le Saint Aubert vous accueille dans un cadre chaleureux et convivial.\\n\\nCet √©tablissement vous propose des chambres paisibles et confortables entour√©es de jardins fleuris.\\n\\nApr√®s une journ√©e de d√©couverte du Mont-Saint-Michel, vous pourrez d√©guster une d√©licieuse cuisine r√©gionale dans le cadre pittoresque d'une ancienne ferme.\\n\\nLe personnel serviable sera heureux de vous recommander un grand nombre de sites d'int√©r√™t et les visites √† faire dans la r√©gion.\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La Caserne, 50170 Le Mont-Saint-Michel, France'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚Ç¨795'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, see the loo for scrping in the 2 .py files in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['https://www.booking.com/searchresults.html?ss=Mont+Saint+Michel&nflt=ht_id=204',\n",
       "  'https://www.booking.com/searchresults.html?ss=Saint+Malo&nflt=ht_id=204',\n",
       "  'https://www.booking.com/searchresults.html?ss=Bayeux&nflt=ht_id=204']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"Saint+Malo\", \"Bayeux\"]\n",
    "\n",
    "start_urls = [\n",
    "        [\"https://www.booking.com/searchresults.html?ss={}&nflt=ht_id=204\".format(city) for city in cities_list],\n",
    "    ]\n",
    "\n",
    "start_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 13:50:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:20 [scrapy.extensions.telnet] INFO: Telnet Password: e991cd360b4e444b\n",
      "2025-02-02 13:50:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 414a285f5b3eecb4\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ad85daf454ae1dff\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ae6d53491a331166\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: af648029a3d1ef82\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 97f87bf5d29f084b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: e79a11f4c24981e6\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 3b84d00651b48351\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 2f1941267f076378\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ba4be9d5c40732e5\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4c7f16746f2f2f73\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: eb3951af16efa367\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 874a6f37b7eeb37c\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: c298ee83db5976ea\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6036\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: b172b8161b5d8f22\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6037\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: dc30e6facfbc14e3\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7a4af23fc93cda3b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6039\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: f33a4dcd950d4774\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6040\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 07d9c776f21212be\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6041\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 37db4f81b561387c\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6042\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7f85e83fa158a41f\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6043\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: aa3cbfc44b99a626\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6044\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 440b293361d9a062\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6045\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: d0349f756b9b45de\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6046\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 67c0e126f6b034b7\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6047\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 5c546e5b939c49c9\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6048\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 8631f28af01241de\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6049\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: eb234f7203ed731d\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6050\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: cd65523673cf991b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6051\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: a787e9feb71a3925\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6052\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: abacdd1ce0db34eb\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6053\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: e5e89902bd3e6d3b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6054\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 633eb174449e8344\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6055\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: afe14ea6a9f755a8\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6056\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 8b5aa85789f0e31b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6057\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Toulouse.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230615,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 4.849165,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 259047, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1235266,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 59,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 409882, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Grenoble.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229664,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.205436,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 441387, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1221386,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 243,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 235951, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Biarritz.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243292,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.261248,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 700889, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1363219,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 43,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 439641, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Aigues+Mortes.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 345,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 244213,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.394853,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 750688, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1334137,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 131,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 355835, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Colmar.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 238262,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.574055,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 750688, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1247355,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 315,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 176633, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Lille.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240374,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.700168,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 848198, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1269351,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 355,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 148030, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Chateau+du+Haut+Koenigsbourg.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 360,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243266,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.689908,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 856145, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1300215,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 335,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 166237, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Montauban.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229508,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.480588,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 906374, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1179821,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 75,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 425786, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Marseille.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242273,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.605032,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 906374, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1279857,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 211,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 301342, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Ariege.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 228381,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.595047,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 989663, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1170369,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 107,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 394616, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Uzes.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 336,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 252568,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.656326,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 999011, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1341701,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 183,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 342685, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Nimes.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230662,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.719073,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 61758, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1218073,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 175,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 342685, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Le+Havre.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230254,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.141409,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 256289, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1238035,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 431,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 114880, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Gorges+du+Verdon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 348,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 228202,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.000177,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 259832, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1178533,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 267,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 259655, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Paris.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241252,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.176478,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 301796, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1296141,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 415,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 125318, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Strasbourg.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 342,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 252216,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.217689,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 373833, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1371832,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 383,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 156144, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Carcassonne.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 343,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 249343,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.068999,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 453086, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1338737,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 147,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 384087, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Rouen.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 238047,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.333856,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 459174, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1258159,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 439,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 125318, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Besancon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229032,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.441636,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 639361, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1191778,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 347,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 197725, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Lyon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 336,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240516,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.51026,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 759643, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1270085,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 303,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 249383, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Avignon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 339,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229257,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.533271,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 856250, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1210767,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 235,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 322979, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bayonne.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 339,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230567,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.450953,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 926752, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1220366,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 107,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 475799, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bormes+les+Mimosas.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 350,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243470,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.702912,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 978072, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1367153,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 291,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 275160, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bayeux.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229821,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.000178,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 106152, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1209445,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 487,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 105974, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Dijon.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 249389,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.087556,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 295421, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1340206,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 359,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 207865, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Mont+Saint+Michel.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 349,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241028,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.234295,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 324192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1282128,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 519,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 89897, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Saintes+Maries+de+la+mer.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 356,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241002,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.960648,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 324192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1318894,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 211,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 363544, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Collioure.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240268,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.960601,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 334368, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1293759,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 203,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 373767, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Cassis.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 235010,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.336356,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 616944, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1270106,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 303,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 280588, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Amiens.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 239842,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.487977,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 627236, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1275676,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 463,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 139259, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Eguisheim.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 251027,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.541171,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 732061, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1338099,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 407,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 190890, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Saint+Malo.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 342,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242637,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.655947,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 758617, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1345114,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 531,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 102670, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:29 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:29 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Annecy.json\n",
      "2025-02-02 13:50:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240282,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 8.181287,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 29, 406295, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1256379,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 379,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 225008, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:29 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:31 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:31 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Aix+en+Provence.json\n",
      "2025-02-02 13:50:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 347,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242577,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 10.242118,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 31, 553952, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1322990,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 299,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 311834, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:31 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:41 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:41 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_La+Rochelle.json\n",
      "2025-02-02 13:50:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 343,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 239360,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 20.253559,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 41, 733461, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1250359,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 147,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 479902, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:41 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! py Scraping/link_scraping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works and we add the json files for the hotels links for each city.  \n",
    "Now, pass to the hotels' informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 2a78d5a7444f8cdf\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 483613a07d7943cc\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: d046afcafd0d3ac1\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: f2a13ac8a4eadbb6\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 3c83baa823663a4f\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 683f474a8735478e\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: a9a4272a79db80d9\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 0b8bab8744e76578\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 479ba3fcbfb0d63b\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: faba60b48baff658\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 28c512c83798cbd3\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 799edecae89ee9ff\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 6c8c5e143ea52a29\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 40121c0b85b0eaf6\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6036\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 3dfb99c46949b38e\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6037\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: c0ab606598f55656\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: a4bc7848eaa1de20\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6039\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 16073ba59d26c6c9\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6040\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 330ff2717884e275\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6041\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 437c81bd6c31bf0b\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6042\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4faf0afe35331ec5\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6043\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: dea33e845bda6ca7\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6044\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: f2cdca2dbd82bc68\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6045\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 45241adaedd09320\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6046\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: ed1b6c4d3867b4f4\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6047\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 5e7528625520d221\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6048\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: caa6c3913cf30bc1\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6049\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 173041ee93afa858\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6050\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 96bcb2888d691cd2\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6051\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 32b54a38c0fd59d4\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6052\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: d57b8290377e7a52\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6053\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 634a947980ab973b\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6054\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: f6091c528faaa9a0\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6055\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: f5e9d767b4f40938\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6056\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: dece483b5307ddb7\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6057\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 9 items (at 9 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/le-jardin-de-verre-by-locke.fr.html?aid=304142&label=gen173nr-1FCAQoggJCDHNlYXJjaF9wYXJpc0gzWARoTYgBAZgBCbgBF8gBDNgBAegBAfgBA4gCAagCA7gCjtT9vAbAAgHSAiQ2Zjc3YTM0NC1jMGM1LTRlMzktODIzNy1hYjA1ZGEyZWYwMzjYAgXgAgE&sid=7ff8ebf0173bbcf262218f477a451f91&dist=0&group_adults=2&group_children=0&hapos=2&hpos=2&keep_landing=1&nflt=ht_id%3D204&no_rooms=1&req_adults=2&req_children=0&sb_price_type=total&sr_order=popularity&srepoch=1738500623&srpvid=b15f5a479f7d0982&type=total&ucfs=1&> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 7 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 8 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 8 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 6 pages/min), scraped 10 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 11 items (at 4 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 13 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 0 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 4 pages/min), scraped 12 items (at 4 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 4 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:34:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/place-de-l-eglise-aubussargues.fr.html?aid=304142&label=gen173nr-1FCAQoggJCC3NlYXJjaF91emVzSDNYBGhNiAEBmAEJuAEXyAEM2AEB6AEB-AEDiAIBqAIDuAKO1P28BsACAdICJGJjMGQyYmIyLTkwYzQtNGU3MS05Zjc1LTc1ZTQyYzFmOWI4ZNgCBeACAQ&sid=be2908d7435c711f1e1ffba731caed58&dist=0&group_adults=2&group_children=0&hapos=18&hpos=18&keep_landing=1&nflt=ht_id%3D204&no_rooms=1&req_adults=2&req_children=0&sb_price_type=total&sr_order=popularity&srepoch=1738500623&srpvid=27a35a4693db011a&type=total&ucfs=1&> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 20:34:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/nnn.fr.html?aid=304142&label=gen173nr-1FCAQoggJCDXNlYXJjaF9jYXNzaXNIM1gEaE2IAQGYAQm4ARfIAQzYAQHoAQH4AQOIAgGoAgO4Ao7U_bwGwAIB0gIkNjQ5NTZiY2UtODViOS00MzlkLWI2NTYtYzk5YjQzNGNhNDE22AIF4AIB&sid=7d62fe0d8bc12ba9c7b23eaa082f5f08&dist=0&group_adults=2&group_children=0&hapos=17&hpos=17&keep_landing=1&nflt=ht_id%3D204&no_rooms=1&req_adults=2&req_children=0&sb_price_type=total&sr_order=popularity&srepoch=1738500623&srpvid=4bff5a462faf0721&type=total&ucfs=1&> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 9 pages/min), scraped 22 items (at 7 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 8 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 17 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 8 pages/min), scraped 16 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 19 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 8 pages/min), scraped 23 items (at 7 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 16 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 16 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 8 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 19 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 16 items (at 0 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 20 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 21 items (at 6 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 20:35:11 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:11 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Mont+Saint+Michel.json\n",
      "2025-02-02 20:35:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58862,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8515533,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 291.040146,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 11, 886446, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32954907,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 559,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 846300, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:11 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 1 pages/min), scraped 24 items (at 8 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 25 items (at 2 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 22 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 24 items (at 7 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 7 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 7 items/min)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Aix+en+Provence.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58587,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8661725,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.347657,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 357970, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33876535,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 345,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 10313, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Grenoble.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58437,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8586732,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.401793,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 360589, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33312177,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 421,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 958796, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Annecy.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58004,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8539608,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.406209,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 362498, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33359042,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 437,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 956289, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Marseille.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58647,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8618381,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.363639,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 363882, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33777645,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 369,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 243, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Amiens.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58161,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8519437,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.471271,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 365898, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32981145,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 541,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 894627, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Lille.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58210,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8549413,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.468258,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 367942, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33175518,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 533,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 899684, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Saint+Malo.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58100,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8922930,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.510504,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 369459, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34407026,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 609,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 858955, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Rouen.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58205,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8584193,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.48915,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 370541, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33429067,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 577,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 881391, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Ariege.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58348,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8569309,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.280462,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 373449, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32920855,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 281,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 92987, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Saintes+Maries+de+la+mer.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 59144,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 9009887,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.315727,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 377453, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35343737,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 321,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 61726, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bayonne.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58079,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8621113,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.233423,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 377453, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33509238,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 241,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 144030, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:40 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Nimes.json\n",
      "2025-02-02 20:35:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 57883,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8663165,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 319.123999,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 40, 171286, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34186166,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 353,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 47287, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:40 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Montauban.json\n",
      "2025-02-02 20:35:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58400,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8447932,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 319.067012,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 40, 173339, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32578882,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 273,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 106327, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:44 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Lyon.json\n",
      "2025-02-02 20:35:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58285,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8627727,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 323.64808,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 44, 617181, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33792006,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 457,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 969101, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:44 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Colmar.json\n",
      "2025-02-02 20:35:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58056,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8636653,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 323.699769,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 44, 622906, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33786336,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 533,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 923137, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Besancon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58274,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8489267,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.050566,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 990347, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32950899,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 513,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 939781, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Gorges+du+Verdon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58745,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8623159,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.017427,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 990347, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33971229,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 457,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 972920, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Collioure.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58204,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8956799,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.917439,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 990347, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35078075,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 341,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 72908, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Avignon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58007,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8680679,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.96988,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34087607,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 405,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 26461, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Paris.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58170,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8633024,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.107841,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33928696,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 613,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 888500, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Dijon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58193,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8590739,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.048069,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33529731,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 521,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 948272, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Biarritz.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58126,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 9051212,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.88299,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35353026,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 297,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 113351, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Le+Havre.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58374,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 9064129,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.123412,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35408985,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 649,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 872929, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Chateau+du+Haut+Koenigsbourg.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 59723,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8641732,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.088559,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 6361, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34047743,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 581,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 917802, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Uzes.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 57800,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8671558,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.976529,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 7269, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34108948,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 417,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 30740, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_La+Rochelle.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58569,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8696601,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.850764,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 7269, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34179364,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 289,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 156505, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Aigues+Mortes.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58768,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8849730,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.949498,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 7269, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34875761,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 401,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 57771, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Toulouse.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58403,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8620602,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.922083,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 15070, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33580506,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 345,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 92987, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Eguisheim.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58516,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8547488,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.087124,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 15070, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33252132,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 577,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 927946, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Cassis.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58029,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8874287,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.021872,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 17178, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34564575,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 485,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 995306, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bayeux.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 57900,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8621005,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.160516,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 27498, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33923647,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 693,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 866982, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Carcassonne.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58445,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8638388,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.946969,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 29574, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33857582,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 385,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 82605, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Strasbourg.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58623,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8666858,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.118796,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 29574, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34051806,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 629,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 910778, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bormes+les+Mimosas.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58734,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8976473,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.042371,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 29574, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35334301,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 513,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 987203, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! py Scraping/hotels_infos_scraping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works, we obtained hotels' infos and put it in different json files for each city.\n",
    "\n",
    "‚ö†Ô∏èNotes : \n",
    "* We just have the 25 first hotels for each city beacause we can't get more url due to the updating of the page on booking.com is done with scrolling. And with scrapy it is not possible to go through that.\n",
    "* Due to my some external reasons, only few hotel's page didn't work (3 on all).\n",
    "* Data was collected the 0/02/2025.\n",
    "* I didn't take the price information because it were missing in some hotel's page because it was not available for reservation at this moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Work on the dataset and put it on S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for cities, localisation and weather:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"St+Malo\", \"Bayeux\", \"Le+Havre\", \"Rouen\", \"Paris\", \"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau+du+Haut+Koenigsbourg\", \"Colmar\",\n",
    "\"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges+du+Verdon\", \"Bormes+les+Mimosas\", \"Cassis\", \"Marseille\", \"Aix+en+Provence\",\n",
    "\"Avignon\", \"Uzes\", \"Nimes\", \"Aigues+Mortes\", \"Saintes+Maries+de+la+mer\", \"Collioure\", \"Carcassonne\", \"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\",\n",
    "\"Bayonne\", \"La+Rochelle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bayeux</td>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Le Havre</td>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               City   Latitude  Longitude Weather  Humidity  Temperature\n",
       "0   1  Mont Saint-Michel  48.635954  -1.511460   Clear      87.0        2.396\n",
       "1   2         Saint-Malo  48.649518  -2.026041  Clouds      85.4        3.996\n",
       "2   3             Bayeux  49.276462  -0.702474   Clear      84.6        2.016\n",
       "3   4           Le Havre  49.493898   0.107973   Clear      76.2        4.318\n",
       "4   5              Rouen  49.440459   1.093966   Clear      82.8        1.982"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data_cities_localisation = pd.read_csv(\"cities_localisation.csv\")\n",
    "\n",
    "data_weather_city = pd.read_csv(\"cities_weather.csv\")\n",
    "\n",
    "data_cities = data_cities_localisation.merge(data_weather_city, on='City')\n",
    "#To move the column city in the first position\n",
    "cities = data_cities.pop('City')\n",
    "data_cities.insert(0, 'City', cities)\n",
    "#To add a first column with the city's id\n",
    "data_cities.insert(0, 'id', [i+1 for i in range(len(cities_list))])\n",
    "data_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cities.to_csv(\"cities_information.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for hotels' informations:  \n",
    "We will try to have only one .csv with all the hotels' informations. We will see later in the ETL part, how to add a foreign key links to the id of the city of the first table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"Saint+Malo\", \"Bayeux\", \"Le+Havre\", \"Rouen\", \"Paris\", \"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau+du+Haut+Koenigsbourg\", \"Colmar\",\n",
    "\"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges+du+Verdon\", \"Bormes+les+Mimosas\", \"Cassis\", \"Marseille\", \"Aix+en+Provence\",\n",
    "\"Avignon\", \"Uzes\", \"Nimes\", \"Aigues+Mortes\", \"Saintes+Maries+de+la+mer\", \"Collioure\", \"Carcassonne\", \"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\",\n",
    "\"Bayonne\", \"La+Rochelle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"Scraping/hotels_infos_per_city/hotels_infos_{}.json\".format(cities_list[25]), \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data_hotels_columns = list(data[0].keys())\n",
    "data_hotels_columns.append(\"City\")\n",
    "data_hotels = pd.DataFrame(columns=data_hotels_columns)\n",
    "data_to_add = []\n",
    "\n",
    "for i in range(len(cities_list)):\n",
    "    data_hotel = pd.read_json(\"Scraping/hotels_infos_per_city/hotels_infos_{}.json\".format(cities_list[i]))\n",
    "    data_hotel[\"City\"] = cities_list[i]\n",
    "\n",
    "    data_to_add.append(data_hotel)\n",
    "\n",
    "\n",
    "data_hotels = pd.concat(data_to_add, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>url_hotel</th>\n",
       "      <th>hotel_coordinates</th>\n",
       "      <th>score</th>\n",
       "      <th>text_description</th>\n",
       "      <th>address</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La M√®re Poulard</td>\n",
       "      <td>https://www.booking.com/hotel/fr/la-mere-poula...</td>\n",
       "      <td>48.63508531723403,-1.5105396509170532</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Install√© dans un b√¢timent historique, cet h√¥te...</td>\n",
       "      <td>Grande Rue, 50170 Le Mont-Saint-Michel, France</td>\n",
       "      <td>Mont+Saint+Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mercure Mont Saint Michel</td>\n",
       "      <td>https://www.booking.com/hotel/fr/mont-saint-mi...</td>\n",
       "      <td>48.61424652959294,-1.510545015335083</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Install√© dans des espaces verts √† seulement 2 ...</td>\n",
       "      <td>La Caserne, 50170 Le Mont-Saint-Michel, France</td>\n",
       "      <td>Mont+Saint+Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le Saint Aubert</td>\n",
       "      <td>https://www.booking.com/hotel/fr/hotel-saint-a...</td>\n",
       "      <td>48.612937834706464,-1.5101051330566406</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Nich√© dans un √©crin de verdure, √† seulement 2 ...</td>\n",
       "      <td>La Caserne, 50170 Le Mont-Saint-Michel, France</td>\n",
       "      <td>Mont+Saint+Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel Gabriel</td>\n",
       "      <td>https://www.booking.com/hotel/fr/hotel-gabriel...</td>\n",
       "      <td>48.61538141368341,-1.510709971189499</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Hotel Gabriel is located 1.6 Km from Mont Sain...</td>\n",
       "      <td>Route du Mont Saint Michel, 50170 Le Mont-Sain...</td>\n",
       "      <td>Mont+Saint+Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H√¥tel la Croix Blanche</td>\n",
       "      <td>https://www.booking.com/hotel/fr/ha-el-la-croi...</td>\n",
       "      <td>48.635734064271254,-1.5098610520362854</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Situ√© au c≈ìur du village m√©di√©val du Mont-Sain...</td>\n",
       "      <td>grande rue, 50170 Le Mont-Saint-Michel, France</td>\n",
       "      <td>Mont+Saint+Michel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  hotel_name  \\\n",
       "0            La M√®re Poulard   \n",
       "1  Mercure Mont Saint Michel   \n",
       "2            Le Saint Aubert   \n",
       "3              Hotel Gabriel   \n",
       "4     H√¥tel la Croix Blanche   \n",
       "\n",
       "                                           url_hotel  \\\n",
       "0  https://www.booking.com/hotel/fr/la-mere-poula...   \n",
       "1  https://www.booking.com/hotel/fr/mont-saint-mi...   \n",
       "2  https://www.booking.com/hotel/fr/hotel-saint-a...   \n",
       "3  https://www.booking.com/hotel/fr/hotel-gabriel...   \n",
       "4  https://www.booking.com/hotel/fr/ha-el-la-croi...   \n",
       "\n",
       "                        hotel_coordinates  score  \\\n",
       "0   48.63508531723403,-1.5105396509170532    7.4   \n",
       "1    48.61424652959294,-1.510545015335083    8.2   \n",
       "2  48.612937834706464,-1.5101051330566406    7.7   \n",
       "3    48.61538141368341,-1.510709971189499    8.2   \n",
       "4  48.635734064271254,-1.5098610520362854    7.8   \n",
       "\n",
       "                                    text_description  \\\n",
       "0  Install√© dans un b√¢timent historique, cet h√¥te...   \n",
       "1  Install√© dans des espaces verts √† seulement 2 ...   \n",
       "2  Nich√© dans un √©crin de verdure, √† seulement 2 ...   \n",
       "3  Hotel Gabriel is located 1.6 Km from Mont Sain...   \n",
       "4  Situ√© au c≈ìur du village m√©di√©val du Mont-Sain...   \n",
       "\n",
       "                                             address               City  \n",
       "0     Grande Rue, 50170 Le Mont-Saint-Michel, France  Mont+Saint+Michel  \n",
       "1     La Caserne, 50170 Le Mont-Saint-Michel, France  Mont+Saint+Michel  \n",
       "2     La Caserne, 50170 Le Mont-Saint-Michel, France  Mont+Saint+Michel  \n",
       "3  Route du Mont Saint Michel, 50170 Le Mont-Sain...  Mont+Saint+Michel  \n",
       "4     grande rue, 50170 Le Mont-Saint-Michel, France  Mont+Saint+Michel  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(872, 7)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_hotels.head())\n",
    "data_hotels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hotels.to_csv(\"hotels_information.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do the maps !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map for the city ranking !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>43.296174</td>\n",
       "      <td>5.369953</td>\n",
       "      <td>Rain</td>\n",
       "      <td>82.8</td>\n",
       "      <td>10.708</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Cassis</td>\n",
       "      <td>43.214036</td>\n",
       "      <td>5.539632</td>\n",
       "      <td>Rain</td>\n",
       "      <td>83.0</td>\n",
       "      <td>9.986</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>Bormes-les-Mimosas</td>\n",
       "      <td>43.150697</td>\n",
       "      <td>6.341928</td>\n",
       "      <td>Rain</td>\n",
       "      <td>85.0</td>\n",
       "      <td>9.458</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>Aix-en-Provence</td>\n",
       "      <td>43.529842</td>\n",
       "      <td>5.447474</td>\n",
       "      <td>Rain</td>\n",
       "      <td>84.8</td>\n",
       "      <td>9.400</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Collioure</td>\n",
       "      <td>42.525050</td>\n",
       "      <td>3.083155</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>62.6</td>\n",
       "      <td>8.956</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                City   Latitude  Longitude Weather  Humidity  \\\n",
       "0  21           Marseille  43.296174   5.369953    Rain      82.8   \n",
       "1  20              Cassis  43.214036   5.539632    Rain      83.0   \n",
       "2  19  Bormes-les-Mimosas  43.150697   6.341928    Rain      85.0   \n",
       "3  22     Aix-en-Provence  43.529842   5.447474    Rain      84.8   \n",
       "4  28           Collioure  42.525050   3.083155  Clouds      62.6   \n",
       "\n",
       "   Temperature  Rank  Rank Size  \n",
       "0       10.708     1         35  \n",
       "1        9.986     2         34  \n",
       "2        9.458     3         33  \n",
       "3        9.400     4         32  \n",
       "4        8.956     5         31  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cities_ranked_by_temp = data_cities.sort_values(by=\"Temperature\", ascending=False).reset_index(drop=True)\n",
    "data_cities_ranked_by_temp[\"Rank\"] = data_cities_ranked_by_temp[\"Temperature\"].rank(ascending=False, method=\"first\").astype(int)\n",
    "data_cities_ranked_by_temp[\"Rank Size\"] = data_cities_ranked_by_temp[\"Temperature\"].rank(ascending=True, method=\"first\").astype(int)\n",
    "data_cities_ranked_by_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Rank Size=%{marker.size}<br>Latitude=%{lat}<br>Longitude=%{lon}<br>Temperature=%{marker.color}<extra></extra>",
         "lat": [
          43.2961743,
          43.2140359,
          43.1506968,
          43.5298424,
          42.52505,
          43.47114375,
          43.4945144,
          43.4515922,
          43.5661521,
          43.9492493,
          43.8374249,
          43.2130358,
          44.0121279,
          43.6044622,
          44.0175835,
          46.159732,
          45.1875602,
          43.7496562,
          45.7578137,
          49.4938975,
          48.649518,
          48.8588897,
          45.8992348,
          50.6365654,
          48.584614,
          48.6359541,
          47.2380222,
          48.0777517,
          49.2764624,
          48.0447968,
          49.4404591,
          47.3215806,
          49.8941708,
          42.9455368,
          48.24941075
         ],
         "legendgroup": "",
         "lon": [
          5.3699525,
          5.5396318,
          6.3419285,
          5.4474738,
          3.0831554,
          -1.552726590666314,
          -1.4736657,
          4.4277202,
          4.19154,
          4.8059012,
          4.3600687,
          2.3491069,
          4.4196718,
          1.4442469,
          1.3549991,
          -1.1515951,
          5.7357819,
          6.3285616,
          4.8320114,
          0.1079732,
          -2.0260409,
          2.3200410217200766,
          6.1288847,
          3.0635282,
          7.7507127,
          -1.511459954959514,
          6.0243622,
          7.3579641,
          -0.7024738,
          7.3079618,
          1.0939658,
          5.0414701,
          2.2956951,
          1.4065544156065486,
          7.344320233724503
         ],
         "marker": {
          "color": [
           10.708,
           9.986,
           9.458,
           9.4,
           8.956,
           8.742,
           8.234,
           7.673999999999999,
           7.49,
           7.006,
           6.85,
           6.812,
           5.924,
           5.822,
           5.352,
           5.279999999999999,
           4.658,
           4.504,
           4.322,
           4.3180000000000005,
           3.996,
           3.858,
           3.856,
           2.592,
           2.568,
           2.396,
           2.1920000000000006,
           2.104,
           2.016,
           2,
           1.982,
           1.966,
           1.8540000000000003,
           0.3179999999999999,
           -0.76
          ],
          "coloraxis": "coloraxis",
          "opacity": 0.5,
          "size": [
           35,
           34,
           33,
           32,
           31,
           30,
           29,
           28,
           27,
           26,
           25,
           24,
           23,
           22,
           21,
           20,
           19,
           18,
           17,
           16,
           15,
           14,
           13,
           12,
           11,
           10,
           9,
           8,
           7,
           6,
           5,
           4,
           3,
           2,
           1
          ],
          "sizemode": "area",
          "sizeref": 0.0875
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "subplot": "mapbox",
         "type": "scattermapbox"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Temperature"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(0,0,255)"
          ],
          [
           1,
           "rgb(255,0,0)"
          ]
         ]
        },
        "height": 512,
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "mapbox": {
         "center": {
          "lat": 45.840991777142854,
          "lon": 3.39592066358358
         },
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "style": "carto-positron",
         "zoom": 4
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 768
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter_mapbox(data_cities_ranked_by_temp, lat=\"Latitude\", lon=\"Longitude\", color=\"Temperature\", size=\"Rank Size\",\n",
    "                        mapbox_style=\"carto-positron\", zoom = 4, color_continuous_scale = 'bluered',\n",
    "                        opacity=0.5,\n",
    "                        width=768,\n",
    "                        height=512)\n",
    "\n",
    "#fig.update_traces(marker=dict(size=30))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rank Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Collioure</td>\n",
       "      <td>42.525050</td>\n",
       "      <td>3.083155</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>62.6</td>\n",
       "      <td>8.956</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Paris</td>\n",
       "      <td>48.858890</td>\n",
       "      <td>2.320041</td>\n",
       "      <td>Clear</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.858</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Carcassonne</td>\n",
       "      <td>43.213036</td>\n",
       "      <td>2.349107</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.812</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Lille</td>\n",
       "      <td>50.636565</td>\n",
       "      <td>3.063528</td>\n",
       "      <td>Clear</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.592</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>48.584614</td>\n",
       "      <td>7.750713</td>\n",
       "      <td>Clear</td>\n",
       "      <td>72.6</td>\n",
       "      <td>2.568</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         City   Latitude  Longitude Weather  Humidity  Temperature  Rank  \\\n",
       "0  28    Collioure  42.525050   3.083155  Clouds      62.6        8.956     1   \n",
       "1   6        Paris  48.858890   2.320041   Clear      68.0        3.858     2   \n",
       "2  29  Carcassonne  43.213036   2.349107  Clouds      69.0        6.812     3   \n",
       "3   8        Lille  50.636565   3.063528   Clear      71.0        2.592     4   \n",
       "4   9   Strasbourg  48.584614   7.750713   Clear      72.6        2.568     5   \n",
       "\n",
       "   Rank Size  \n",
       "0         35  \n",
       "1         34  \n",
       "2         33  \n",
       "3         32  \n",
       "4         31  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cities_ranked_by_hum = data_cities.sort_values(by=\"Humidity\", ascending=True).reset_index(drop=True)\n",
    "data_cities_ranked_by_hum[\"Rank\"] = data_cities_ranked_by_hum[\"Humidity\"].rank(ascending=True, method=\"first\").astype(int)\n",
    "data_cities_ranked_by_hum[\"Rank Size\"] = data_cities_ranked_by_hum[\"Humidity\"].rank(ascending=False, method=\"first\").astype(int)\n",
    "data_cities_ranked_by_hum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>Rank Size=%{marker.size}<br>Latitude=%{lat}<br>Longitude=%{lon}<br>Humidity=%{marker.color}<extra></extra>",
         "hovertext": [
          "Collioure",
          "Paris",
          "Carcassonne",
          "Lille",
          "Strasbourg",
          "Toulouse",
          "Avignon",
          "Montauban",
          "Le Havre",
          "Amiens",
          "N√Æmes",
          "Uz√®s",
          "Lyon",
          "La Rochelle",
          "Colmar",
          "Eguisheim",
          "Saintes-Maries-de-la-Mer",
          "Ch√¢teau du Haut-K≈ìnigsbourg",
          "Biarritz",
          "Gorges du Verdon",
          "Bayonne",
          "Aigues-Mortes",
          "Marseille",
          "Rouen",
          "Cassis",
          "Bayeux",
          "Aix-en-Provence",
          "Bormes-les-Mimosas",
          "Saint-Malo",
          "Dijon",
          "Ari√®ge",
          "Mont Saint-Michel",
          "Annecy",
          "Besan√ßon",
          "Grenoble"
         ],
         "lat": [
          42.52505,
          48.8588897,
          43.2130358,
          50.6365654,
          48.584614,
          43.6044622,
          43.9492493,
          44.0175835,
          49.4938975,
          49.8941708,
          43.8374249,
          44.0121279,
          45.7578137,
          46.159732,
          48.0777517,
          48.0447968,
          43.4515922,
          48.24941075,
          43.47114375,
          43.7496562,
          43.4945144,
          43.5661521,
          43.2961743,
          49.4404591,
          43.2140359,
          49.2764624,
          43.5298424,
          43.1506968,
          48.649518,
          47.3215806,
          42.9455368,
          48.6359541,
          45.8992348,
          47.2380222,
          45.1875602
         ],
         "legendgroup": "",
         "lon": [
          3.0831554,
          2.3200410217200766,
          2.3491069,
          3.0635282,
          7.7507127,
          1.4442469,
          4.8059012,
          1.3549991,
          0.1079732,
          2.2956951,
          4.3600687,
          4.4196718,
          4.8320114,
          -1.1515951,
          7.3579641,
          7.3079618,
          4.4277202,
          7.344320233724503,
          -1.552726590666314,
          6.3285616,
          -1.4736657,
          4.19154,
          5.3699525,
          1.0939658,
          5.5396318,
          -0.7024738,
          5.4474738,
          6.3419285,
          -2.0260409,
          5.0414701,
          1.4065544156065486,
          -1.511459954959514,
          6.1288847,
          6.0243622,
          5.7357819
         ],
         "marker": {
          "color": [
           62.6,
           68,
           69,
           71,
           72.6,
           73,
           74.6,
           75.2,
           76.2,
           76.2,
           76.6,
           76.8,
           78,
           78.8,
           78.8,
           78.8,
           79.2,
           80,
           80.6,
           81.6,
           82.2,
           82.4,
           82.8,
           82.8,
           83,
           84.6,
           84.8,
           85,
           85.4,
           85.6,
           87,
           87,
           88,
           88,
           92.4
          ],
          "coloraxis": "coloraxis",
          "opacity": 0.5,
          "size": [
           35,
           34,
           33,
           32,
           31,
           30,
           29,
           28,
           26,
           27,
           25,
           24,
           23,
           20,
           21,
           22,
           19,
           18,
           17,
           16,
           15,
           14,
           12,
           13,
           11,
           10,
           9,
           8,
           7,
           6,
           4,
           5,
           2,
           3,
           1
          ],
          "sizemode": "area",
          "sizeref": 0.0875
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "subplot": "mapbox",
         "type": "scattermapbox"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Humidity"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(231, 250, 90)"
          ],
          [
           0.09090909090909091,
           "rgb(246, 211, 70)"
          ],
          [
           0.18181818181818182,
           "rgb(251, 173, 60)"
          ],
          [
           0.2727272727272727,
           "rgb(246, 139, 69)"
          ],
          [
           0.36363636363636365,
           "rgb(225, 113, 97)"
          ],
          [
           0.45454545454545453,
           "rgb(193, 100, 121)"
          ],
          [
           0.5454545454545454,
           "rgb(158, 89, 135)"
          ],
          [
           0.6363636363636364,
           "rgb(126, 77, 143)"
          ],
          [
           0.7272727272727273,
           "rgb(93, 62, 153)"
          ],
          [
           0.8181818181818182,
           "rgb(53, 50, 155)"
          ],
          [
           0.9090909090909091,
           "rgb(13, 48, 100)"
          ],
          [
           1,
           "rgb(3, 35, 51)"
          ]
         ]
        },
        "height": 512,
        "legend": {
         "itemsizing": "constant",
         "tracegroupgap": 0
        },
        "mapbox": {
         "center": {
          "lat": 45.840991777142854,
          "lon": 3.39592066358358
         },
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "style": "carto-positron",
         "zoom": 4
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 768
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter_mapbox(data_cities_ranked_by_hum, lat=\"Latitude\", lon=\"Longitude\", color=\"Humidity\", size=\"Rank Size\", hover_name=\"City\",\n",
    "                        mapbox_style=\"carto-positron\", zoom = 4, color_continuous_scale = 'thermal_r',\n",
    "                        opacity=0.5,\n",
    "                        width=768,\n",
    "                        height=512)\n",
    "\n",
    "#fig.update_traces(marker=dict(size=30))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Latitude=%{lat}<br>Longitude=%{lon}<br>Temperature=%{marker.color}<extra></extra>",
         "lat": [
          43.2961743,
          43.2140359,
          43.1506968,
          43.5298424,
          42.52505
         ],
         "legendgroup": "",
         "lon": [
          5.3699525,
          5.5396318,
          6.3419285,
          5.4474738,
          3.0831554
         ],
         "marker": {
          "color": [
           10.708,
           9.986,
           9.458,
           9.4,
           8.956
          ],
          "coloraxis": "coloraxis",
          "opacity": 0.7,
          "size": 15
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "subplot": "mapbox",
         "type": "scattermapbox"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Temperature"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(0,0,255)"
          ],
          [
           1,
           "rgb(255,0,0)"
          ]
         ]
        },
        "height": 512,
        "legend": {
         "tracegroupgap": 0
        },
        "mapbox": {
         "center": {
          "lat": 43.14315988,
          "lon": 5.1564284
         },
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "style": "carto-positron",
         "zoom": 3.5
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 768
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter_mapbox(data_cities_ranked_by_temp[:5], lat=\"Latitude\", lon=\"Longitude\", color=\"Temperature\", \n",
    "                        mapbox_style=\"carto-positron\", zoom = 3.5, color_continuous_scale = 'bluered',\n",
    "                        opacity=0.7,\n",
    "                        width=768,\n",
    "                        height=512)\n",
    "\n",
    "fig.update_traces(marker=dict(size=15))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map for the hotels ranking !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - ETL, create a database and put the cleaned and reworked data on it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
