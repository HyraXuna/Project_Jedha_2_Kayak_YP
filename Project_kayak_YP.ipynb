{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd project for the bloc 1 of the Jedha certification of data science & engineering.\n",
    "Author : Youenn Patat\n",
    "\n",
    "![Kayak](https://seekvectorlogo.com/wp-content/uploads/2018/01/kayak-vector-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of cities than we will focus ourselves:\n",
    "```python \n",
    "[\"Mont Saint Michel\",\n",
    "\"St Malo\",\n",
    "\"Bayeux\",\n",
    "\"Le Havre\",\n",
    "\"Rouen\",\n",
    "\"Paris\",\n",
    "\"Amiens\",\n",
    "\"Lille\",\n",
    "\"Strasbourg\",\n",
    "\"Chateau du Haut Koenigsbourg\",\n",
    "\"Colmar\",\n",
    "\"Eguisheim\",\n",
    "\"Besancon\",\n",
    "\"Dijon\",\n",
    "\"Annecy\",\n",
    "\"Grenoble\",\n",
    "\"Lyon\",\n",
    "\"Gorges du Verdon\",\n",
    "\"Bormes les Mimosas\",\n",
    "\"Cassis\",\n",
    "\"Marseille\",\n",
    "\"Aix en Provence\",\n",
    "\"Avignon\",\n",
    "\"Uzes\",\n",
    "\"Nimes\",\n",
    "\"Aigues Mortes\",\n",
    "\"Saintes Maries de la mer\",\n",
    "\"Collioure\",\n",
    "\"Carcassonne\",\n",
    "\"Ariege\",\n",
    "\"Toulouse\",\n",
    "\"Montauban\",\n",
    "\"Biarritz\",\n",
    "\"Bayonne\",\n",
    "\"La Rochelle\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Get the weather and localisation with API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two different APIs used: \n",
    "*   https://nominatim.org/ to get the gps coordinates of all the cities (no subscription required) Documentation : https://nominatim.org/release-docs/develop/api/Search/\n",
    "\n",
    "*   https://openweathermap.org/appid (you have to subscribe to get a free apikey) and https://openweathermap.org/api/one-call-api to get some information about the weather for the 35 cities and put it in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1rst test with just the Mont Saint Michel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://nominatim.openstreetmap.org/search?q=\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "r = requests.get(url+\"Mont+Saint+Michel&format=json\", headers=headers)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place_id': 263784127,\n",
       " 'licence': 'Data ¬© OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n",
       " 'osm_type': 'way',\n",
       " 'osm_id': 211285890,\n",
       " 'lat': '48.6359541',\n",
       " 'lon': '-1.511459954959514',\n",
       " 'class': 'tourism',\n",
       " 'type': 'attraction',\n",
       " 'place_rank': 30,\n",
       " 'importance': 0.4723710249003365,\n",
       " 'addresstype': 'tourism',\n",
       " 'name': 'Mont Saint-Michel',\n",
       " 'display_name': \"Mont Saint-Michel, Grande Terrasse de l'Ouest, Le Mont-Saint-Michel, Avranches, Manche, Normandie, France m√©tropolitaine, 50170, France\",\n",
       " 'boundingbox': ['48.6349172', '48.6370310', '-1.5133292', '-1.5094796']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': '48.6359541', 'lon': '-1.511459954959514', 'name': 'Mont Saint-Michel'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = {key: value for key, value in r.json()[0].items() if 'lat' in key or 'lon' in key or 'name' in key}\n",
    "del coordinates['display_name']\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works !!! We obtained the `json` of informations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lat', 'lon', 'name'])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lat, lon, name]\n",
       "Index: []"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = coordinates.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will loop with all the city names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"St+Malo\", \"Bayeux\", \"Le+Havre\", \"Rouen\", \"Paris\", \"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau+du+Haut+Koenigsbourg\", \"Colmar\",\n",
    "\"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges+du+Verdon\", \"Bormes+les+Mimosas\", \"Cassis\", \"Marseille\", \"Aix+en+Provence\",\n",
    "\"Avignon\", \"Uzes\", \"Nimes\", \"Aigues+Mortes\", \"Saintes+Maries+de+la+mer\", \"Collioure\", \"Carcassonne\", \"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\",\n",
    "\"Bayonne\", \"La+Rochelle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 city done <Response [200]>\n",
      "2 city done <Response [200]>\n",
      "3 city done <Response [200]>\n",
      "4 city done <Response [200]>\n",
      "5 city done <Response [200]>\n",
      "6 city done <Response [200]>\n",
      "7 city done <Response [200]>\n",
      "8 city done <Response [200]>\n",
      "9 city done <Response [200]>\n",
      "10 city done <Response [200]>\n",
      "11 city done <Response [200]>\n",
      "12 city done <Response [200]>\n",
      "13 city done <Response [200]>\n",
      "14 city done <Response [200]>\n",
      "15 city done <Response [200]>\n",
      "16 city done <Response [200]>\n",
      "17 city done <Response [200]>\n",
      "18 city done <Response [200]>\n",
      "19 city done <Response [200]>\n",
      "20 city done <Response [200]>\n",
      "21 city done <Response [200]>\n",
      "22 city done <Response [200]>\n",
      "23 city done <Response [200]>\n",
      "24 city done <Response [200]>\n",
      "25 city done <Response [200]>\n",
      "26 city done <Response [200]>\n",
      "27 city done <Response [200]>\n",
      "28 city done <Response [200]>\n",
      "29 city done <Response [200]>\n",
      "30 city done <Response [200]>\n",
      "31 city done <Response [200]>\n",
      "32 city done <Response [200]>\n",
      "33 city done <Response [200]>\n",
      "34 city done <Response [200]>\n",
      "35 city done <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://nominatim.openstreetmap.org/search?q=\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "for i in range(len(cities_list)):\n",
    "    r = requests.get(url+cities_list[i]+\"&format=json\", headers=headers)\n",
    "    print(\"{} city done\".format(i+1), r)\n",
    "    coordinates = {key: value for key, value in r.json()[0].items() if key in ['lat', 'lon', 'name']}\n",
    "    df.loc[i] = coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.6359541</td>\n",
       "      <td>-1.511459954959514</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.0260409</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.2764624</td>\n",
       "      <td>-0.7024738</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.4938975</td>\n",
       "      <td>0.1079732</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.4404591</td>\n",
       "      <td>1.0939658</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude           Longitude               Name\n",
       "0  48.6359541  -1.511459954959514  Mont Saint-Michel\n",
       "1   48.649518          -2.0260409         Saint-Malo\n",
       "2  49.2764624          -0.7024738             Bayeux\n",
       "3  49.4938975           0.1079732           Le Havre\n",
       "4  49.4404591           1.0939658              Rouen"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'lat':'Latitude', 'lon':'Longitude', 'name':'Name'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cities_localisation.csv\", index=False, encoding=\"utf-8\")\n",
    "df.to_json(\"city_localisation.json\", orient=\"records\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude               Name\n",
       "0  48.635954  -1.511460  Mont Saint-Michel\n",
       "1  48.649518  -2.026041         Saint-Malo\n",
       "2  49.276462  -0.702474             Bayeux\n",
       "3  49.493898   0.107973           Le Havre\n",
       "4  49.440459   1.093966              Rouen"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude               Name\n",
       "0  48.635954  -1.511460  Mont Saint-Michel\n",
       "1  48.649518  -2.026041         Saint-Malo\n",
       "2  49.276462  -0.702474             Bayeux\n",
       "3  49.493898   0.107973           Le Havre\n",
       "4  49.440459   1.093966              Rouen"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_json(\"city_localisation.json\")\n",
    "display(df2.head())\n",
    "\n",
    "df3 = pd.read_csv(\"cities_localisation.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the informations about meteo with the second API.\n",
    "\n",
    "Beginning with a test with one city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "weather_api_key = os.environ['WEATHER_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://api.openweathermap.org/data/2.5/weather?q=London,uk&APPID=b63df840e68ed1fabade0a250d87401b\n",
    "lat = df3['Latitude'][0]\n",
    "lon = df3['Longitude'][0]\n",
    "\n",
    "#url = \"https://api.openweathermap.org/data/2.5/weather?lat={}&lon={}&appid={}\".format(lat, lon, weather_api_key) #for current daily weather\n",
    "url = \"https://api.openweathermap.org/data/2.5/forecast?lat={}&lon={}&appid={}&units=metric\".format(lat, lon, weather_api_key) #for 5 days forecast\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "r = requests.get(url, headers=headers)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dt': 1738486800,\n",
       "  'main': {'temp': 1.62,\n",
       "   'feels_like': -2.05,\n",
       "   'temp_min': 1.62,\n",
       "   'temp_max': 1.62,\n",
       "   'pressure': 1021,\n",
       "   'sea_level': 1021,\n",
       "   'grnd_level': 1016,\n",
       "   'humidity': 83,\n",
       "   'temp_kf': 0},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 5},\n",
       "  'wind': {'speed': 3.65, 'deg': 149, 'gust': 7.53},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 09:00:00'},\n",
       " {'dt': 1738497600,\n",
       "  'main': {'temp': 3.2,\n",
       "   'feels_like': -0.05,\n",
       "   'temp_min': 3.2,\n",
       "   'temp_max': 6.35,\n",
       "   'pressure': 1021,\n",
       "   'sea_level': 1021,\n",
       "   'grnd_level': 1017,\n",
       "   'humidity': 77,\n",
       "   'temp_kf': -3.15},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 5},\n",
       "  'wind': {'speed': 3.53, 'deg': 169, 'gust': 4.71},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 12:00:00'},\n",
       " {'dt': 1738508400,\n",
       "  'main': {'temp': 5.79,\n",
       "   'feels_like': 4.02,\n",
       "   'temp_min': 5.79,\n",
       "   'temp_max': 7.87,\n",
       "   'pressure': 1022,\n",
       "   'sea_level': 1022,\n",
       "   'grnd_level': 1017,\n",
       "   'humidity': 69,\n",
       "   'temp_kf': -2.08},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 2},\n",
       "  'wind': {'speed': 2.28, 'deg': 185, 'gust': 3.03},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 15:00:00'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['list'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Clouds\n",
      "1    Clouds\n",
      "2     Clear\n",
      "3     Clear\n",
      "4     Clear\n",
      "dtype: object\n",
      "Average weather will be: Clear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    81\n",
       "1    85\n",
       "2    90\n",
       "3    90\n",
       "4    89\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    4.98\n",
       "1    3.80\n",
       "2    2.16\n",
       "3    0.95\n",
       "4    0.09\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean humidity: 87.0 ; mean temperature: 2.396\n"
     ]
    }
   ],
   "source": [
    "meteo_forecaste = []\n",
    "for i in range(len(r.json())):\n",
    "    meteo_forecaste.append(r.json()['list'][i]['weather'][0]['main'])\n",
    "\n",
    "meteo_forecaste = pd.Series(meteo_forecaste)\n",
    "print(meteo_forecaste)\n",
    "mean_meteo = meteo_forecaste.value_counts().idxmax()\n",
    "print('Average weather will be:', mean_meteo)\n",
    "\n",
    "humidity_forecaste = []\n",
    "temp_forecaste = []\n",
    "for i in range(len(r.json())):\n",
    "    humidity_forecaste.append(r.json()['list'][i]['main']['humidity'])\n",
    "    temp_forecaste.append(r.json()['list'][i]['main']['temp'])\n",
    "\n",
    "humidity_forecaste = pd.Series(humidity_forecaste)\n",
    "temp_forecaste = pd.Series(temp_forecaste)\n",
    "display(humidity_forecaste)\n",
    "display(temp_forecaste)\n",
    "\n",
    "mean_humidity = humidity_forecaste.mean()\n",
    "mean_temp = temp_forecaste.mean()\n",
    "\n",
    "print('mean humidity:', mean_humidity, '; mean temperature:', mean_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we saw that we can have mean humidity, mean temperature and average weather for the forecaste of 5 days for one location. So we will loop this to obtain all these informations for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, Weather, Humidity, Temperature]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janz√©</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City Weather  Humidity  Temperature\n",
       "0  Janz√©   Cloud      4.25           18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_weather = pd.DataFrame( columns = [\"City\", \"Weather\", \"Humidity\", \"Temperature\"])\n",
    "display(df_weather)\n",
    "\n",
    "value1 = 'Janz√©'\n",
    "value2 = 'Cloud'\n",
    "value3 = 4.25\n",
    "value4 =18\n",
    "\n",
    "df_weather.loc[0] = [value1, value2, value3, value4]\n",
    "\n",
    "display(df_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 city weather informations collected <Response [200]>\n",
      "2 city weather informations collected <Response [200]>\n",
      "3 city weather informations collected <Response [200]>\n",
      "4 city weather informations collected <Response [200]>\n",
      "5 city weather informations collected <Response [200]>\n",
      "6 city weather informations collected <Response [200]>\n",
      "7 city weather informations collected <Response [200]>\n",
      "8 city weather informations collected <Response [200]>\n",
      "9 city weather informations collected <Response [200]>\n",
      "10 city weather informations collected <Response [200]>\n",
      "11 city weather informations collected <Response [200]>\n",
      "12 city weather informations collected <Response [200]>\n",
      "13 city weather informations collected <Response [200]>\n",
      "14 city weather informations collected <Response [200]>\n",
      "15 city weather informations collected <Response [200]>\n",
      "16 city weather informations collected <Response [200]>\n",
      "17 city weather informations collected <Response [200]>\n",
      "18 city weather informations collected <Response [200]>\n",
      "19 city weather informations collected <Response [200]>\n",
      "20 city weather informations collected <Response [200]>\n",
      "21 city weather informations collected <Response [200]>\n",
      "22 city weather informations collected <Response [200]>\n",
      "23 city weather informations collected <Response [200]>\n",
      "24 city weather informations collected <Response [200]>\n",
      "25 city weather informations collected <Response [200]>\n",
      "26 city weather informations collected <Response [200]>\n",
      "27 city weather informations collected <Response [200]>\n",
      "28 city weather informations collected <Response [200]>\n",
      "29 city weather informations collected <Response [200]>\n",
      "30 city weather informations collected <Response [200]>\n",
      "31 city weather informations collected <Response [200]>\n",
      "32 city weather informations collected <Response [200]>\n",
      "33 city weather informations collected <Response [200]>\n",
      "34 city weather informations collected <Response [200]>\n",
      "35 city weather informations collected <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "df_cities = pd.read_csv(\"cities_localisation.csv\")\n",
    "\n",
    "df_weather = pd.DataFrame( columns = [\"City\", \"Weather\", \"Humidity\", \"Temperature\"])\n",
    "\n",
    "for i in range(len(cities_list)):\n",
    "    lat = df_cities['Latitude'][i]\n",
    "    lon = df_cities['Longitude'][i]\n",
    "\n",
    "    url = \"https://api.openweathermap.org/data/2.5/forecast?lat={}&lon={}&appid={}&units=metric\".format(lat, lon, weather_api_key) #for 5 days forecast\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "\n",
    "    meteo_forecaste = []\n",
    "    for weather_description in range(len(r.json())):\n",
    "        meteo_forecaste.append(r.json()['list'][weather_description]['weather'][0]['main'])\n",
    "\n",
    "    meteo_forecaste = pd.Series(meteo_forecaste)\n",
    "    mean_meteo = meteo_forecaste.value_counts().idxmax()\n",
    "\n",
    "    humidity_forecaste = []\n",
    "    temp_forecaste = []\n",
    "    for hum_temp in range(len(r.json())):\n",
    "        humidity_forecaste.append(r.json()['list'][hum_temp]['main']['humidity'])\n",
    "        temp_forecaste.append(r.json()['list'][hum_temp]['main']['temp'])\n",
    "\n",
    "    humidity_forecaste = pd.Series(humidity_forecaste)\n",
    "    temp_forecaste = pd.Series(temp_forecaste)\n",
    "    \n",
    "\n",
    "    mean_humidity = humidity_forecaste.mean()\n",
    "    mean_temp = temp_forecaste.mean()\n",
    "\n",
    "    df_weather.loc[i] = [df_cities['Name'][i], mean_meteo, mean_humidity, mean_temp]\n",
    "\n",
    "    print(\"{} city weather informations collected\".format(i+1), r)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_csv(\"cities_weather.csv\", index=False, encoding=\"utf-8\")\n",
    "df_weather.to_json(\"city_weather.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_2 = pd.read_json(\"city_weather.json\")\n",
    "display(df_weather_2.head())\n",
    "\n",
    "df_weather_3 = pd.read_csv(\"cities_weather.csv\")\n",
    "df_weather_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we completed this part and obtained a csv and json file with the city's name associated to the mean weather, humidity and temperature for the next 5 days.  \n",
    "‚ö†Ô∏è It was done the 1srt of February, so the meteo data is not very good for any place in France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Get the hotels infos with the web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web scraping will be done on Booking https://www.booking.com/index.fr.html\n",
    "\n",
    "Informations to scrape:\n",
    "*   hotel name,\n",
    "*   Url to its booking.com page,\n",
    "*   Its coordinates: latitude and longitude\n",
    "*   Score given by the website users\n",
    "*   Text description of the hotel\n",
    "*   Address\n",
    "*   Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will do the testing phase for scraping. When it will be done we will loop it in a spider file (.py file) and store all the data in json files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st step : loop for each city the scraping to get the url page for each hotel. Collect all in multiples json files, 1 per city.  \n",
    "\n",
    "2nd step : loop for each page to get the infos for the hotels, and collect all the data in a json file for each city.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector query=None data='<html><head><script type=\"text/javasc...'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "#url for test for hotels at Mont Saint Michel\n",
    "#https://www.booking.com/searchresults.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ss=Le+Mont-Saint-Michel%C+France&efdco=1&lang=fr&src=index&dest_id=900039327&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=d4b23b24d4940325&checkin=2025-02-02&checkout=2025-02-09&group_adults=2&no_rooms=1&group_children=0&nflt=ht_id%3D204\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "url = \"https://www.booking.com/searchresults.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ss=Le+Mont-Saint-Michel%C+France&efdco=1&lang=fr&src=index&dest_id=900039327&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=d4b23b24d4940325&checkin=2025-02-02&checkout=2025-02-09&group_adults=2&no_rooms=1&group_children=0&nflt=ht_id%3D204\"\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "response = Selector(text=r.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_url = response.css(\"a[class='a78ca197d0']\").attrib[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.booking.com/hotel/fr/hotel-saint-aubert.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-02-02&checkout=2025-02-09&dest_id=900039327&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=916b42ff1a7605b5&srepoch=1738488703&all_sr_blocks=23081103_347524575_0_2_0&highlighted_blocks=23081103_347524575_0_2_0&matching_block_id=23081103_347524575_0_2_0&sr_pri_blocks=23081103_347524575_0_2_0__93120&from=searchresults'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works üëç!\n",
    "\n",
    "Now see for the 2nd step with hotel info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector query=None data='<html><head><script type=\"text/javasc...'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "url = hotel_url\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "response = Selector(text=r.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_name = response.css(\"h2[class='d2fee87262 pp-header__title']::text\").get()\n",
    "url_hotel = url\n",
    "hotel_coordinates = response.css(\"a[id='map_trigger_header']::attr(data-atlas-latlng)\").get()\n",
    "score = response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.')\n",
    "text_description = response.css(\"p[class='a53cbfa6de b3efd73f69']::text\").get()\n",
    "address = response.css(\"div[class='a53cbfa6de f17adf7576']::text\").get()\n",
    "price_week = response.css(\"span[class='prco-valign-middle-helper']::text\").get().replace(\"\\xa0\", \"\").replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le Saint Aubert'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.booking.com/hotel/fr/hotel-saint-aubert.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-02-02&checkout=2025-02-09&dest_id=900039327&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=916b42ff1a7605b5&srepoch=1738488703&all_sr_blocks=23081103_347524575_0_2_0&highlighted_blocks=23081103_347524575_0_2_0&matching_block_id=23081103_347524575_0_2_0&sr_pri_blocks=23081103_347524575_0_2_0__93120&from=searchresults'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48.612937834706464,-1.5101051330566406'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.7'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nich√© dans un √©crin de verdure, √† seulement 2 km du Mont-Saint-Michel, Le Saint Aubert vous accueille dans un cadre chaleureux et convivial.\\n\\nCet √©tablissement vous propose des chambres paisibles et confortables entour√©es de jardins fleuris.\\n\\nApr√®s une journ√©e de d√©couverte du Mont-Saint-Michel, vous pourrez d√©guster une d√©licieuse cuisine r√©gionale dans le cadre pittoresque d'une ancienne ferme.\\n\\nLe personnel serviable sera heureux de vous recommander un grand nombre de sites d'int√©r√™t et les visites √† faire dans la r√©gion.\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La Caserne, 50170 Le Mont-Saint-Michel, France'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚Ç¨795'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, see the loo for scrping in the 2 .py files in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['https://www.booking.com/searchresults.html?ss=Mont+Saint+Michel&nflt=ht_id=204',\n",
       "  'https://www.booking.com/searchresults.html?ss=Saint+Malo&nflt=ht_id=204',\n",
       "  'https://www.booking.com/searchresults.html?ss=Bayeux&nflt=ht_id=204']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"Saint+Malo\", \"Bayeux\"]\n",
    "\n",
    "start_urls = [\n",
    "        [\"https://www.booking.com/searchresults.html?ss={}&nflt=ht_id=204\".format(city) for city in cities_list],\n",
    "    ]\n",
    "\n",
    "start_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 13:50:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:20 [scrapy.extensions.telnet] INFO: Telnet Password: e991cd360b4e444b\n",
      "2025-02-02 13:50:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 414a285f5b3eecb4\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ad85daf454ae1dff\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ae6d53491a331166\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: af648029a3d1ef82\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 97f87bf5d29f084b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: e79a11f4c24981e6\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 3b84d00651b48351\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 2f1941267f076378\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ba4be9d5c40732e5\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4c7f16746f2f2f73\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: eb3951af16efa367\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 874a6f37b7eeb37c\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: c298ee83db5976ea\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6036\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: b172b8161b5d8f22\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6037\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: dc30e6facfbc14e3\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7a4af23fc93cda3b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6039\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: f33a4dcd950d4774\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6040\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 07d9c776f21212be\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6041\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 37db4f81b561387c\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6042\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7f85e83fa158a41f\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6043\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: aa3cbfc44b99a626\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6044\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 440b293361d9a062\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6045\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: d0349f756b9b45de\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6046\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 67c0e126f6b034b7\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6047\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 5c546e5b939c49c9\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6048\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 8631f28af01241de\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6049\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: eb234f7203ed731d\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6050\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: cd65523673cf991b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6051\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: a787e9feb71a3925\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6052\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: abacdd1ce0db34eb\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6053\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: e5e89902bd3e6d3b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6054\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 633eb174449e8344\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6055\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: afe14ea6a9f755a8\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6056\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 8b5aa85789f0e31b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6057\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Toulouse.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230615,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 4.849165,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 259047, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1235266,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 59,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 409882, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Grenoble.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229664,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.205436,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 441387, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1221386,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 243,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 235951, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Biarritz.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243292,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.261248,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 700889, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1363219,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 43,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 439641, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Aigues+Mortes.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 345,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 244213,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.394853,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 750688, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1334137,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 131,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 355835, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Colmar.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 238262,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.574055,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 750688, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1247355,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 315,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 176633, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Lille.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240374,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.700168,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 848198, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1269351,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 355,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 148030, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Chateau+du+Haut+Koenigsbourg.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 360,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243266,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.689908,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 856145, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1300215,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 335,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 166237, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Montauban.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229508,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.480588,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 906374, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1179821,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 75,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 425786, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Marseille.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242273,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.605032,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 906374, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1279857,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 211,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 301342, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Ariege.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 228381,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.595047,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 989663, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1170369,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 107,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 394616, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Uzes.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 336,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 252568,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.656326,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 999011, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1341701,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 183,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 342685, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Nimes.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230662,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.719073,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 61758, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1218073,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 175,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 342685, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Le+Havre.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230254,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.141409,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 256289, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1238035,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 431,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 114880, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Gorges+du+Verdon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 348,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 228202,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.000177,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 259832, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1178533,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 267,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 259655, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Paris.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241252,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.176478,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 301796, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1296141,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 415,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 125318, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Strasbourg.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 342,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 252216,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.217689,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 373833, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1371832,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 383,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 156144, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Carcassonne.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 343,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 249343,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.068999,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 453086, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1338737,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 147,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 384087, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Rouen.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 238047,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.333856,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 459174, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1258159,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 439,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 125318, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Besancon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229032,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.441636,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 639361, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1191778,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 347,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 197725, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Lyon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 336,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240516,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.51026,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 759643, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1270085,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 303,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 249383, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Avignon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 339,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229257,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.533271,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 856250, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1210767,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 235,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 322979, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bayonne.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 339,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230567,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.450953,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 926752, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1220366,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 107,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 475799, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bormes+les+Mimosas.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 350,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243470,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.702912,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 978072, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1367153,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 291,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 275160, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bayeux.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229821,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.000178,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 106152, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1209445,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 487,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 105974, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Dijon.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 249389,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.087556,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 295421, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1340206,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 359,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 207865, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Mont+Saint+Michel.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 349,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241028,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.234295,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 324192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1282128,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 519,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 89897, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Saintes+Maries+de+la+mer.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 356,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241002,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.960648,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 324192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1318894,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 211,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 363544, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Collioure.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240268,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.960601,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 334368, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1293759,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 203,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 373767, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Cassis.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 235010,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.336356,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 616944, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1270106,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 303,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 280588, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Amiens.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 239842,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.487977,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 627236, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1275676,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 463,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 139259, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Eguisheim.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 251027,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.541171,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 732061, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1338099,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 407,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 190890, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Saint+Malo.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 342,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242637,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.655947,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 758617, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1345114,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 531,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 102670, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:29 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:29 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Annecy.json\n",
      "2025-02-02 13:50:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240282,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 8.181287,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 29, 406295, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1256379,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 379,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 225008, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:29 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:31 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:31 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Aix+en+Provence.json\n",
      "2025-02-02 13:50:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 347,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242577,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 10.242118,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 31, 553952, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1322990,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 299,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 311834, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:31 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:41 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:41 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_La+Rochelle.json\n",
      "2025-02-02 13:50:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 343,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 239360,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 20.253559,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 41, 733461, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1250359,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 147,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 479902, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:41 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! py Scraping/link_scraping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works and we add the json files for the hotels links for each city.  \n",
    "Now, pass to the hotels' informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 17:45:44 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:44 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:44 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:44 [scrapy.extensions.telnet] INFO: Telnet Password: 72648cc36a9562a5\n",
      "2025-02-02 17:45:44 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:44 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 4632055db4e11967\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 154133da4bd93990\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 580136cfc35f5a5e\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 3606b0814752405d\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 10f9b34ba650208b\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 719111f67f29e18c\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 78df085f2618f2e2\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 6b98ac6e497e61b7\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 68d1ec1d65ec7bf5\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 46609b142be7aa78\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 16076869291284c1\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 6e7d46299a1c9a8f\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 2dd07ebd04f2a54c\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6036\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 1512a7abf87ab497\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6037\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 44c54b623e087f8f\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 70baf8a5603cb17c\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6039\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: f0a1ac28938c5c25\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6040\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: cfa43ac5aabcf6f5\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6041\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 777daf1fd7d45a7a\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6042\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 19fa0e75312c1ce0\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6043\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 0a9323fc836767a4\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6044\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 556acfa5420937ac\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6045\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 430d4ec755995cd7\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6046\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 4e11f56a6530bfd5\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6047\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 7a7f41acbda03696\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6048\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 133b2a4b66fe3f17\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6049\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 1d7192559e9ce5bb\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6050\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: f3d70c5a387d2874\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6051\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: c22ffa76105dd2be\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6052\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 637e698891019744\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6053\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 041f390bcadd509b\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6054\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 59abc1e55a13d366\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6055\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: 65cda34238fba043\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6056\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 17:45:45 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 17:45:45 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet Password: a6e87820f283f34e\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 17:45:45 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 17:45:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 17:45:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 17:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:45:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6057\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 3 items (at 3 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 5 items (at 5 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 3 items (at 3 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 3 items (at 3 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 2 items (at 2 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 1 items (at 1 items/min)\n",
      "2025-02-02 17:46:51 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 3 items (at 3 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 3 pages/min), scraped 5 items (at 3 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 7 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 5 items (at 3 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 6 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 3 pages/min), scraped 6 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 9 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 3 pages/min), scraped 6 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 9 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 6 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 3 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 9 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 5 items (at 3 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 4 pages/min), scraped 4 items (at 2 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 8 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 1 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 3 pages/min), scraped 6 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 4 pages/min), scraped 6 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 2 pages/min), scraped 8 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 3 pages/min), scraped 7 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 1 pages/min), scraped 5 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 6 items (at 5 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 6 items/min)\n",
      "2025-02-02 17:48:22 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 2 pages/min), scraped 7 items (at 4 items/min)\n",
      "2025-02-02 17:48:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/le-jardin-de-verre-by-locke.en-gb.html?aid=304142&label=gen173nr-1FCAQoggJCDHNlYXJjaF9wYXJpc0gzWARoTYgBAZgBCbgBF8gBDNgBAegBAfgBA4gCAagCA7gCjtT9vAbAAgHSAiQ2Zjc3YTM0NC1jMGM1LTRlMzktODIzNy1hYjA1ZGEyZWYwMzjYAgXgAgE&ucfs=1&arphpl=1&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=b15f5a479f7d0982&srepoch=1738500623&from=searchresults> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 8 items (at 3 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 8 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 7 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 7 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 6 items (at 0 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 7 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 10 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 3 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 1 pages/min), scraped 9 items (at 0 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 10 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 8 items (at 3 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 7 items (at 0 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 7 items (at 3 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 0 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 1 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 0 pages/min), scraped 8 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 7 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 0 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 2 pages/min), scraped 6 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 1 pages/min), scraped 7 items (at 1 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 0 pages/min), scraped 12 items (at 4 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 17:48:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 13 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 11 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 11 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 8 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 11 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 14 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 8 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 14 items (at 7 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 7 pages/min), scraped 14 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 14 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 7 pages/min), scraped 17 items (at 8 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 13 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 12 items (at 3 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 12 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 8 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 6 pages/min), scraped 14 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 13 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 12 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 12 items (at 3 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 7 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 7 pages/min), scraped 14 items (at 5 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 13 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 12 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 5 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 8 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 8 pages/min), scraped 14 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 12 items (at 6 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 14 items (at 7 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 8 pages/min), scraped 13 items (at 1 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 13 items (at 4 items/min)\n",
      "2025-02-02 17:50:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 8 pages/min), scraped 14 items (at 5 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 14 items (at 1 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 15 items (at 1 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 14 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 14 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 13 items (at 2 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 17 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 14 items (at 0 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 1 pages/min), scraped 18 items (at 4 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 16 items (at 2 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 1 pages/min), scraped 17 items (at 0 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 16 items (at 4 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 15 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 15 items (at 1 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 15 items (at 2 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 2 pages/min), scraped 15 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 13 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 15 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 1 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 1 pages/min), scraped 15 items (at 1 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 16 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 15 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 14 items (at 5 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 3 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 16 items (at 0 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 18 items (at 4 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 14 items (at 2 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 14 items (at 0 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 16 items (at 3 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 17 items (at 4 items/min)\n",
      "2025-02-02 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 16 items (at 2 items/min)\n",
      "2025-02-02 17:51:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/place-de-l-eglise-aubussargues.en-gb.html?aid=304142&label=gen173nr-1FCAQoggJCC3NlYXJjaF91emVzSDNYBGhNiAEBmAEJuAEXyAEM2AEB6AEB-AEDiAIBqAIDuAKO1P28BsACAdICJGJjMGQyYmIyLTkwYzQtNGU3MS05Zjc1LTc1ZTQyYzFmOWI4ZNgCBeACAQ&ucfs=1&arphpl=1&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=18&hapos=18&sr_order=popularity&nflt=ht_id%3D204&srpvid=27a35a4693db011a&srepoch=1738500623&from=searchresults> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 17 items (at 3 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 2 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 2 pages/min), scraped 17 items (at 3 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 16 items (at 2 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 19 items (at 1 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 2 pages/min), scraped 15 items (at 2 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 2 pages/min), scraped 18 items (at 1 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 4 pages/min), scraped 18 items (at 1 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 17 items (at 3 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 3 pages/min), scraped 19 items (at 1 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 2 pages/min), scraped 20 items (at 3 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 2 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 17:51:49 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 17:51:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/nnn.en-gb.html?aid=304142&label=gen173nr-1FCAQoggJCDXNlYXJjaF9jYXNzaXNIM1gEaE2IAQGYAQm4ARfIAQzYAQHoAQH4AQOIAgGoAgO4Ao7U_bwGwAIB0gIkNjQ5NTZiY2UtODViOS00MzlkLWI2NTYtYzk5YjQzNGNhNDE22AIF4AIB&ucfs=1&arphpl=1&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=17&hapos=17&sr_order=popularity&nflt=ht_id%3D204&srpvid=4bff5a462faf0721&srepoch=1738500623&from=searchresults> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 17:51:53 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 1 pages/min), scraped 16 items (at 1 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 2 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 4 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 2 pages/min), scraped 16 items (at 3 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 19 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 2 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 19 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 2 pages/min), scraped 16 items (at 1 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 17 items (at 3 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 19 items (at 1 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 4 pages/min), scraped 17 items (at 3 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 18 items (at 4 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 1 pages/min), scraped 18 items (at 1 items/min)\n",
      "2025-02-02 17:51:58 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 19 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 20 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 4 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 3 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 21 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 19 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 0 pages/min), scraped 19 items (at 1 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 1 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 0 pages/min), scraped 22 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 2 pages/min), scraped 23 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 0 pages/min), scraped 18 items (at 1 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 2 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 1 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 0 pages/min), scraped 22 items (at 1 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 0 pages/min), scraped 20 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 4 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 3 pages/min), scraped 19 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 1 pages/min), scraped 21 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 0 pages/min), scraped 19 items (at 1 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 21 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 2 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 21 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 3 pages/min), scraped 20 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 20 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 2 pages/min), scraped 20 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 1 pages/min), scraped 22 items (at 3 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 1 pages/min), scraped 19 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 2 pages/min), scraped 22 items (at 4 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 3 pages/min), scraped 22 items (at 2 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 1 pages/min), scraped 19 items (at 1 items/min)\n",
      "2025-02-02 17:52:52 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 0 pages/min), scraped 21 items (at 2 items/min)\n",
      "2025-02-02 17:53:14 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:14 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Montauban.json\n",
      "2025-02-02 17:53:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 24535,\n",
      " 'downloader/request_count': 25,\n",
      " 'downloader/request_method_count/GET': 25,\n",
      " 'downloader/response_bytes': 8004202,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 448.519457,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 14, 51716, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31327861,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 292,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 25,\n",
      " 'scheduler/dequeued/memory': 25,\n",
      " 'scheduler/enqueued': 25,\n",
      " 'scheduler/enqueued/memory': 25,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 532259, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:14 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:22 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:22 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Uzes.json\n",
      "2025-02-02 17:53:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 24243,\n",
      " 'downloader/request_count': 25,\n",
      " 'downloader/request_method_count/GET': 25,\n",
      " 'downloader/response_bytes': 8207593,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 456.789237,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 22, 256078, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32526011,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 392,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 25,\n",
      " 'scheduler/dequeued/memory': 25,\n",
      " 'scheduler/enqueued': 25,\n",
      " 'scheduler/enqueued/memory': 25,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 466841, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:22 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:28 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Cassis.json\n",
      "2025-02-02 17:53:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 24298,\n",
      " 'downloader/request_count': 25,\n",
      " 'downloader/request_method_count/GET': 25,\n",
      " 'downloader/response_bytes': 8421428,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 462.817808,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 28, 251884, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32970674,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 444,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 25,\n",
      " 'scheduler/dequeued/memory': 25,\n",
      " 'scheduler/enqueued': 25,\n",
      " 'scheduler/enqueued/memory': 25,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 434076, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:31 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:31 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Eguisheim.json\n",
      "2025-02-02 17:53:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25989,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8145281,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 465.877309,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 31, 236866, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32075068,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 544,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 359557, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:31 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:31 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:31 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bayeux.json\n",
      "2025-02-02 17:53:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 24211,\n",
      " 'downloader/request_count': 25,\n",
      " 'downloader/request_method_count/GET': 25,\n",
      " 'downloader/response_bytes': 8215494,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 465.960383,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 31, 236866, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32667204,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 656,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 25,\n",
      " 'scheduler/dequeued/memory': 25,\n",
      " 'scheduler/enqueued': 25,\n",
      " 'scheduler/enqueued/memory': 25,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 276483, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:31 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:57 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Grenoble.json\n",
      "2025-02-02 17:53:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 3,\n",
      " 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 28957,\n",
      " 'downloader/request_count': 28,\n",
      " 'downloader/request_method_count/GET': 28,\n",
      " 'downloader/response_bytes': 8121560,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 491.613819,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 57, 4592, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31800030,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 504,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 3,\n",
      " 'retry/reason_count/twisted.internet.error.TimeoutError': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 28,\n",
      " 'scheduler/dequeued/memory': 28,\n",
      " 'scheduler/enqueued': 28,\n",
      " 'scheduler/enqueued/memory': 28,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 390773, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:57 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:57 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bormes+les+Mimosas.json\n",
      "2025-02-02 17:53:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27521,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8587112,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 491.59431,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 53, 57, 15937, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34156774,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 472,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 421627, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:53:57 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 22 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 6 pages/min), scraped 22 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 24 items (at 1 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 7 pages/min), scraped 21 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 24 items (at 2 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 7 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 24 items (at 2 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 24 items (at 4 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 6 pages/min), scraped 22 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 24 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 24 items (at 4 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 22 items (at 2 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 22 items (at 2 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 23 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 25 items (at 6 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 24 items (at 2 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 6 pages/min), scraped 22 items (at 3 items/min)\n",
      "2025-02-02 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Mont+Saint+Michel.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 26196,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8129220,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.313705,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 569494, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32010503,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 720,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 255789, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Le+Havre.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25913,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8604989,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.282583,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 569494, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33773232,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 688,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 286911, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Saint+Malo.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25732,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8514225,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.304984,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 572462, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33156639,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 716,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 267478, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Chateau+du+Haut+Koenigsbourg.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 28103,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8161479,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.2335,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 572462, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32396015,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 624,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 338962, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Toulouse.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27419,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8184022,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.055587,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 572462, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32225446,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 376,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 516875, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Ariege.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25862,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8110407,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.058827,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 575233, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31424876,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 392,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 516406, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Marseille.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27640,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8215332,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 505.13359,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 576512, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32613387,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 504,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 442922, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:10 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_La+Rochelle.json\n",
      "2025-02-02 17:54:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27454,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8232515,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 504.992816,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 10, 576512, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32631302,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 340,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 583696, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:10 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Strasbourg.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 26053,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8222787,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.132505,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 466285, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32529382,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 656,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 333780, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Nimes.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 3,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,\n",
      " 'downloader/request_bytes': 28522,\n",
      " 'downloader/request_count': 28,\n",
      " 'downloader/request_method_count/GET': 28,\n",
      " 'downloader/response_bytes': 8201669,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 509.992316,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 466285, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32544758,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 468,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 3,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 3,\n",
      " 'scheduler/dequeued': 28,\n",
      " 'scheduler/dequeued/memory': 28,\n",
      " 'scheduler/enqueued': 28,\n",
      " 'scheduler/enqueued/memory': 28,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 473969, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Aigues+Mortes.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27538,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8423913,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 509.982676,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 466285, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33549357,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 460,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 483609, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Biarritz.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25746,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8629698,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 509.930312,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 466285, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34034874,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 380,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 535973, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Annecy.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27258,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8150332,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.083137,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 466285, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32153429,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 600,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 383148, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Lyon.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 3,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,\n",
      " 'downloader/request_bytes': 28828,\n",
      " 'downloader/request_count': 28,\n",
      " 'downloader/request_method_count/GET': 28,\n",
      " 'downloader/response_bytes': 8191518,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.084418,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 475191, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32342091,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 580,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 3,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 3,\n",
      " 'scheduler/dequeued': 28,\n",
      " 'scheduler/dequeued/memory': 28,\n",
      " 'scheduler/enqueued': 28,\n",
      " 'scheduler/enqueued/memory': 28,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 390773, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Rouen.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27223,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8183750,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.184321,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 475191, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32411265,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 728,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 290870, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Dijon.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27257,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8170520,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.105461,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 475191, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32261123,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 624,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 369730, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Colmar.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25897,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8238300,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.124933,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 475191, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32643553,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 664,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 350258, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Gorges+du+Verdon.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 26152,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8143179,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 510.066204,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 475191, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32275475,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 584,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 408987, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:15 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Carcassonne.json\n",
      "2025-02-02 17:54:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 2,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'downloader/request_bytes': 27451,\n",
      " 'downloader/request_count': 27,\n",
      " 'downloader/request_method_count/GET': 27,\n",
      " 'downloader/response_bytes': 8217678,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 509.977443,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 15, 482098, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32695805,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 456,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 2,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,\n",
      " 'scheduler/dequeued': 27,\n",
      " 'scheduler/dequeued/memory': 27,\n",
      " 'scheduler/enqueued': 27,\n",
      " 'scheduler/enqueued/memory': 27,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 504655, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:15 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 17:54:16 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 17:54:16 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Lille.json\n",
      "2025-02-02 17:54:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 1,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 25875,\n",
      " 'downloader/request_count': 26,\n",
      " 'downloader/request_method_count/GET': 26,\n",
      " 'downloader/response_bytes': 8148514,\n",
      " 'downloader/response_count': 25,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'elapsed_time_seconds': 511.249942,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 16, 54, 16, 569763, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32024303,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 712,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'retry/count': 1,\n",
      " 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'scheduler/dequeued': 26,\n",
      " 'scheduler/dequeued/memory': 26,\n",
      " 'scheduler/enqueued': 26,\n",
      " 'scheduler/enqueued/memory': 26,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 16, 45, 45, 319821, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 17:54:16 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! py Scraping/hotels_infos_scraping.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
