{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd project for the bloc 1 of the Jedha certification of data science & engineering.\n",
    "Author : Youenn Patat\n",
    "\n",
    "![Kayak](https://seekvectorlogo.com/wp-content/uploads/2018/01/kayak-vector-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of cities than we will focus ourselves:\n",
    "```python \n",
    "[\"Mont Saint Michel\",\n",
    "\"St Malo\",\n",
    "\"Bayeux\",\n",
    "\"Le Havre\",\n",
    "\"Rouen\",\n",
    "\"Paris\",\n",
    "\"Amiens\",\n",
    "\"Lille\",\n",
    "\"Strasbourg\",\n",
    "\"Chateau du Haut Koenigsbourg\",\n",
    "\"Colmar\",\n",
    "\"Eguisheim\",\n",
    "\"Besancon\",\n",
    "\"Dijon\",\n",
    "\"Annecy\",\n",
    "\"Grenoble\",\n",
    "\"Lyon\",\n",
    "\"Gorges du Verdon\",\n",
    "\"Bormes les Mimosas\",\n",
    "\"Cassis\",\n",
    "\"Marseille\",\n",
    "\"Aix en Provence\",\n",
    "\"Avignon\",\n",
    "\"Uzes\",\n",
    "\"Nimes\",\n",
    "\"Aigues Mortes\",\n",
    "\"Saintes Maries de la mer\",\n",
    "\"Collioure\",\n",
    "\"Carcassonne\",\n",
    "\"Ariege\",\n",
    "\"Toulouse\",\n",
    "\"Montauban\",\n",
    "\"Biarritz\",\n",
    "\"Bayonne\",\n",
    "\"La Rochelle\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Get the weather and localisation with API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two different APIs used: \n",
    "*   https://nominatim.org/ to get the gps coordinates of all the cities (no subscription required) Documentation : https://nominatim.org/release-docs/develop/api/Search/\n",
    "\n",
    "*   https://openweathermap.org/appid (you have to subscribe to get a free apikey) and https://openweathermap.org/api/one-call-api to get some information about the weather for the 35 cities and put it in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1rst test with just the Mont Saint Michel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://nominatim.openstreetmap.org/search?q=\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "r = requests.get(url+\"Mont+Saint+Michel&format=json\", headers=headers)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place_id': 263784127,\n",
       " 'licence': 'Data ¬© OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n",
       " 'osm_type': 'way',\n",
       " 'osm_id': 211285890,\n",
       " 'lat': '48.6359541',\n",
       " 'lon': '-1.511459954959514',\n",
       " 'class': 'tourism',\n",
       " 'type': 'attraction',\n",
       " 'place_rank': 30,\n",
       " 'importance': 0.4723710249003365,\n",
       " 'addresstype': 'tourism',\n",
       " 'name': 'Mont Saint-Michel',\n",
       " 'display_name': \"Mont Saint-Michel, Grande Terrasse de l'Ouest, Le Mont-Saint-Michel, Avranches, Manche, Normandie, France m√©tropolitaine, 50170, France\",\n",
       " 'boundingbox': ['48.6349172', '48.6370310', '-1.5133292', '-1.5094796']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': '48.6359541', 'lon': '-1.511459954959514', 'name': 'Mont Saint-Michel'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = {key: value for key, value in r.json()[0].items() if 'lat' in key or 'lon' in key or 'name' in key}\n",
    "del coordinates['display_name']\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works !!! We obtained the `json` of informations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lat', 'lon', 'name'])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lat, lon, name]\n",
       "Index: []"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = coordinates.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will loop with all the city names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"St+Malo\", \"Bayeux\", \"Le+Havre\", \"Rouen\", \"Paris\", \"Amiens\", \"Lille\", \"Strasbourg\", \"Chateau+du+Haut+Koenigsbourg\", \"Colmar\",\n",
    "\"Eguisheim\", \"Besancon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\", \"Gorges+du+Verdon\", \"Bormes+les+Mimosas\", \"Cassis\", \"Marseille\", \"Aix+en+Provence\",\n",
    "\"Avignon\", \"Uzes\", \"Nimes\", \"Aigues+Mortes\", \"Saintes+Maries+de+la+mer\", \"Collioure\", \"Carcassonne\", \"Ariege\", \"Toulouse\", \"Montauban\", \"Biarritz\",\n",
    "\"Bayonne\", \"La+Rochelle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 city done <Response [200]>\n",
      "2 city done <Response [200]>\n",
      "3 city done <Response [200]>\n",
      "4 city done <Response [200]>\n",
      "5 city done <Response [200]>\n",
      "6 city done <Response [200]>\n",
      "7 city done <Response [200]>\n",
      "8 city done <Response [200]>\n",
      "9 city done <Response [200]>\n",
      "10 city done <Response [200]>\n",
      "11 city done <Response [200]>\n",
      "12 city done <Response [200]>\n",
      "13 city done <Response [200]>\n",
      "14 city done <Response [200]>\n",
      "15 city done <Response [200]>\n",
      "16 city done <Response [200]>\n",
      "17 city done <Response [200]>\n",
      "18 city done <Response [200]>\n",
      "19 city done <Response [200]>\n",
      "20 city done <Response [200]>\n",
      "21 city done <Response [200]>\n",
      "22 city done <Response [200]>\n",
      "23 city done <Response [200]>\n",
      "24 city done <Response [200]>\n",
      "25 city done <Response [200]>\n",
      "26 city done <Response [200]>\n",
      "27 city done <Response [200]>\n",
      "28 city done <Response [200]>\n",
      "29 city done <Response [200]>\n",
      "30 city done <Response [200]>\n",
      "31 city done <Response [200]>\n",
      "32 city done <Response [200]>\n",
      "33 city done <Response [200]>\n",
      "34 city done <Response [200]>\n",
      "35 city done <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://nominatim.openstreetmap.org/search?q=\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "for i in range(len(cities_list)):\n",
    "    r = requests.get(url+cities_list[i]+\"&format=json\", headers=headers)\n",
    "    print(\"{} city done\".format(i+1), r)\n",
    "    coordinates = {key: value for key, value in r.json()[0].items() if key in ['lat', 'lon', 'name']}\n",
    "    df.loc[i] = coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.6359541</td>\n",
       "      <td>-1.511459954959514</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.0260409</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.2764624</td>\n",
       "      <td>-0.7024738</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.4938975</td>\n",
       "      <td>0.1079732</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.4404591</td>\n",
       "      <td>1.0939658</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude           Longitude               Name\n",
       "0  48.6359541  -1.511459954959514  Mont Saint-Michel\n",
       "1   48.649518          -2.0260409         Saint-Malo\n",
       "2  49.2764624          -0.7024738             Bayeux\n",
       "3  49.4938975           0.1079732           Le Havre\n",
       "4  49.4404591           1.0939658              Rouen"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'lat':'Latitude', 'lon':'Longitude', 'name':'Name'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cities_localisation.csv\", index=False, encoding=\"utf-8\")\n",
    "df.to_json(\"city_localisation.json\", orient=\"records\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude               Name\n",
       "0  48.635954  -1.511460  Mont Saint-Michel\n",
       "1  48.649518  -2.026041         Saint-Malo\n",
       "2  49.276462  -0.702474             Bayeux\n",
       "3  49.493898   0.107973           Le Havre\n",
       "4  49.440459   1.093966              Rouen"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "      <td>Saint-Malo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "      <td>Bayeux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude               Name\n",
       "0  48.635954  -1.511460  Mont Saint-Michel\n",
       "1  48.649518  -2.026041         Saint-Malo\n",
       "2  49.276462  -0.702474             Bayeux\n",
       "3  49.493898   0.107973           Le Havre\n",
       "4  49.440459   1.093966              Rouen"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_json(\"city_localisation.json\")\n",
    "display(df2.head())\n",
    "\n",
    "df3 = pd.read_csv(\"cities_localisation.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the informations about meteo with the second API.\n",
    "\n",
    "Beginning with a test with one city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "weather_api_key = os.environ['WEATHER_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://api.openweathermap.org/data/2.5/weather?q=London,uk&APPID=b63df840e68ed1fabade0a250d87401b\n",
    "lat = df3['Latitude'][0]\n",
    "lon = df3['Longitude'][0]\n",
    "\n",
    "#url = \"https://api.openweathermap.org/data/2.5/weather?lat={}&lon={}&appid={}\".format(lat, lon, weather_api_key) #for current daily weather\n",
    "url = \"https://api.openweathermap.org/data/2.5/forecast?lat={}&lon={}&appid={}&units=metric\".format(lat, lon, weather_api_key) #for 5 days forecast\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "r = requests.get(url, headers=headers)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dt': 1738486800,\n",
       "  'main': {'temp': 1.62,\n",
       "   'feels_like': -2.05,\n",
       "   'temp_min': 1.62,\n",
       "   'temp_max': 1.62,\n",
       "   'pressure': 1021,\n",
       "   'sea_level': 1021,\n",
       "   'grnd_level': 1016,\n",
       "   'humidity': 83,\n",
       "   'temp_kf': 0},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 5},\n",
       "  'wind': {'speed': 3.65, 'deg': 149, 'gust': 7.53},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 09:00:00'},\n",
       " {'dt': 1738497600,\n",
       "  'main': {'temp': 3.2,\n",
       "   'feels_like': -0.05,\n",
       "   'temp_min': 3.2,\n",
       "   'temp_max': 6.35,\n",
       "   'pressure': 1021,\n",
       "   'sea_level': 1021,\n",
       "   'grnd_level': 1017,\n",
       "   'humidity': 77,\n",
       "   'temp_kf': -3.15},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 5},\n",
       "  'wind': {'speed': 3.53, 'deg': 169, 'gust': 4.71},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 12:00:00'},\n",
       " {'dt': 1738508400,\n",
       "  'main': {'temp': 5.79,\n",
       "   'feels_like': 4.02,\n",
       "   'temp_min': 5.79,\n",
       "   'temp_max': 7.87,\n",
       "   'pressure': 1022,\n",
       "   'sea_level': 1022,\n",
       "   'grnd_level': 1017,\n",
       "   'humidity': 69,\n",
       "   'temp_kf': -2.08},\n",
       "  'weather': [{'id': 800,\n",
       "    'main': 'Clear',\n",
       "    'description': 'clear sky',\n",
       "    'icon': '01d'}],\n",
       "  'clouds': {'all': 2},\n",
       "  'wind': {'speed': 2.28, 'deg': 185, 'gust': 3.03},\n",
       "  'visibility': 10000,\n",
       "  'pop': 0,\n",
       "  'sys': {'pod': 'd'},\n",
       "  'dt_txt': '2025-02-02 15:00:00'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['list'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Clouds\n",
      "1    Clouds\n",
      "2     Clear\n",
      "3     Clear\n",
      "4     Clear\n",
      "dtype: object\n",
      "Average weather will be: Clear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    81\n",
       "1    85\n",
       "2    90\n",
       "3    90\n",
       "4    89\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    4.98\n",
       "1    3.80\n",
       "2    2.16\n",
       "3    0.95\n",
       "4    0.09\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean humidity: 87.0 ; mean temperature: 2.396\n"
     ]
    }
   ],
   "source": [
    "meteo_forecaste = []\n",
    "for i in range(len(r.json())):\n",
    "    meteo_forecaste.append(r.json()['list'][i]['weather'][0]['main'])\n",
    "\n",
    "meteo_forecaste = pd.Series(meteo_forecaste)\n",
    "print(meteo_forecaste)\n",
    "mean_meteo = meteo_forecaste.value_counts().idxmax()\n",
    "print('Average weather will be:', mean_meteo)\n",
    "\n",
    "humidity_forecaste = []\n",
    "temp_forecaste = []\n",
    "for i in range(len(r.json())):\n",
    "    humidity_forecaste.append(r.json()['list'][i]['main']['humidity'])\n",
    "    temp_forecaste.append(r.json()['list'][i]['main']['temp'])\n",
    "\n",
    "humidity_forecaste = pd.Series(humidity_forecaste)\n",
    "temp_forecaste = pd.Series(temp_forecaste)\n",
    "display(humidity_forecaste)\n",
    "display(temp_forecaste)\n",
    "\n",
    "mean_humidity = humidity_forecaste.mean()\n",
    "mean_temp = temp_forecaste.mean()\n",
    "\n",
    "print('mean humidity:', mean_humidity, '; mean temperature:', mean_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we saw that we can have mean humidity, mean temperature and average weather for the forecaste of 5 days for one location. So we will loop this to obtain all these informations for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, Weather, Humidity, Temperature]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janz√©</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City Weather  Humidity  Temperature\n",
       "0  Janz√©   Cloud      4.25           18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_weather = pd.DataFrame( columns = [\"City\", \"Weather\", \"Humidity\", \"Temperature\"])\n",
    "display(df_weather)\n",
    "\n",
    "value1 = 'Janz√©'\n",
    "value2 = 'Cloud'\n",
    "value3 = 4.25\n",
    "value4 =18\n",
    "\n",
    "df_weather.loc[0] = [value1, value2, value3, value4]\n",
    "\n",
    "display(df_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 city weather informations collected <Response [200]>\n",
      "2 city weather informations collected <Response [200]>\n",
      "3 city weather informations collected <Response [200]>\n",
      "4 city weather informations collected <Response [200]>\n",
      "5 city weather informations collected <Response [200]>\n",
      "6 city weather informations collected <Response [200]>\n",
      "7 city weather informations collected <Response [200]>\n",
      "8 city weather informations collected <Response [200]>\n",
      "9 city weather informations collected <Response [200]>\n",
      "10 city weather informations collected <Response [200]>\n",
      "11 city weather informations collected <Response [200]>\n",
      "12 city weather informations collected <Response [200]>\n",
      "13 city weather informations collected <Response [200]>\n",
      "14 city weather informations collected <Response [200]>\n",
      "15 city weather informations collected <Response [200]>\n",
      "16 city weather informations collected <Response [200]>\n",
      "17 city weather informations collected <Response [200]>\n",
      "18 city weather informations collected <Response [200]>\n",
      "19 city weather informations collected <Response [200]>\n",
      "20 city weather informations collected <Response [200]>\n",
      "21 city weather informations collected <Response [200]>\n",
      "22 city weather informations collected <Response [200]>\n",
      "23 city weather informations collected <Response [200]>\n",
      "24 city weather informations collected <Response [200]>\n",
      "25 city weather informations collected <Response [200]>\n",
      "26 city weather informations collected <Response [200]>\n",
      "27 city weather informations collected <Response [200]>\n",
      "28 city weather informations collected <Response [200]>\n",
      "29 city weather informations collected <Response [200]>\n",
      "30 city weather informations collected <Response [200]>\n",
      "31 city weather informations collected <Response [200]>\n",
      "32 city weather informations collected <Response [200]>\n",
      "33 city weather informations collected <Response [200]>\n",
      "34 city weather informations collected <Response [200]>\n",
      "35 city weather informations collected <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "df_cities = pd.read_csv(\"cities_localisation.csv\")\n",
    "\n",
    "df_weather = pd.DataFrame( columns = [\"City\", \"Weather\", \"Humidity\", \"Temperature\"])\n",
    "\n",
    "for i in range(len(cities_list)):\n",
    "    lat = df_cities['Latitude'][i]\n",
    "    lon = df_cities['Longitude'][i]\n",
    "\n",
    "    url = \"https://api.openweathermap.org/data/2.5/forecast?lat={}&lon={}&appid={}&units=metric\".format(lat, lon, weather_api_key) #for 5 days forecast\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "\n",
    "    meteo_forecaste = []\n",
    "    for weather_description in range(len(r.json())):\n",
    "        meteo_forecaste.append(r.json()['list'][weather_description]['weather'][0]['main'])\n",
    "\n",
    "    meteo_forecaste = pd.Series(meteo_forecaste)\n",
    "    mean_meteo = meteo_forecaste.value_counts().idxmax()\n",
    "\n",
    "    humidity_forecaste = []\n",
    "    temp_forecaste = []\n",
    "    for hum_temp in range(len(r.json())):\n",
    "        humidity_forecaste.append(r.json()['list'][hum_temp]['main']['humidity'])\n",
    "        temp_forecaste.append(r.json()['list'][hum_temp]['main']['temp'])\n",
    "\n",
    "    humidity_forecaste = pd.Series(humidity_forecaste)\n",
    "    temp_forecaste = pd.Series(temp_forecaste)\n",
    "    \n",
    "\n",
    "    mean_humidity = humidity_forecaste.mean()\n",
    "    mean_temp = temp_forecaste.mean()\n",
    "\n",
    "    df_weather.loc[i] = [df_cities['Name'][i], mean_meteo, mean_humidity, mean_temp]\n",
    "\n",
    "    print(\"{} city weather informations collected\".format(i+1), r)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_csv(\"cities_weather.csv\", index=False, encoding=\"utf-8\")\n",
    "df_weather.to_json(\"city_weather.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont Saint-Michel</td>\n",
       "      <td>Clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint-Malo</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>85.4</td>\n",
       "      <td>3.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayeux</td>\n",
       "      <td>Clear</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Havre</td>\n",
       "      <td>Clear</td>\n",
       "      <td>76.2</td>\n",
       "      <td>4.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rouen</td>\n",
       "      <td>Clear</td>\n",
       "      <td>82.8</td>\n",
       "      <td>1.982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City Weather  Humidity  Temperature\n",
       "0  Mont Saint-Michel   Clear      87.0        2.396\n",
       "1         Saint-Malo  Clouds      85.4        3.996\n",
       "2             Bayeux   Clear      84.6        2.016\n",
       "3           Le Havre   Clear      76.2        4.318\n",
       "4              Rouen   Clear      82.8        1.982"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_2 = pd.read_json(\"city_weather.json\")\n",
    "display(df_weather_2.head())\n",
    "\n",
    "df_weather_3 = pd.read_csv(\"cities_weather.csv\")\n",
    "df_weather_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we completed this part and obtained a csv and json file with the city's name associated to the mean weather, humidity and temperature for the next 5 days.  \n",
    "‚ö†Ô∏è It was done the 1srt of February, so the meteo data is not very good for any place in France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Get the hotels infos with the web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web scraping will be done on Booking https://www.booking.com/index.fr.html\n",
    "\n",
    "Informations to scrape:\n",
    "*   hotel name,\n",
    "*   Url to its booking.com page,\n",
    "*   Its coordinates: latitude and longitude\n",
    "*   Score given by the website users\n",
    "*   Text description of the hotel\n",
    "*   Address\n",
    "*   Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will do the testing phase for scraping. When it will be done we will loop it in a spider file (.py file) and store all the data in json files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st step : loop for each city the scraping to get the url page for each hotel. Collect all in multiples json files, 1 per city.  \n",
    "\n",
    "2nd step : loop for each page to get the infos for the hotels, and collect all the data in a json file for each city.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector query=None data='<html><head><script type=\"text/javasc...'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "#url for test for hotels at Mont Saint Michel\n",
    "#https://www.booking.com/searchresults.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ss=Le+Mont-Saint-Michel%C+France&efdco=1&lang=fr&src=index&dest_id=900039327&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=d4b23b24d4940325&checkin=2025-02-02&checkout=2025-02-09&group_adults=2&no_rooms=1&group_children=0&nflt=ht_id%3D204\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "url = \"https://www.booking.com/searchresults.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ss=Le+Mont-Saint-Michel%C+France&efdco=1&lang=fr&src=index&dest_id=900039327&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=fr&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=d4b23b24d4940325&checkin=2025-02-02&checkout=2025-02-09&group_adults=2&no_rooms=1&group_children=0&nflt=ht_id%3D204\"\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "response = Selector(text=r.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_url = response.css(\"a[class='a78ca197d0']\").attrib[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.booking.com/hotel/fr/hotel-saint-aubert.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-02-02&checkout=2025-02-09&dest_id=900039327&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=916b42ff1a7605b5&srepoch=1738488703&all_sr_blocks=23081103_347524575_0_2_0&highlighted_blocks=23081103_347524575_0_2_0&matching_block_id=23081103_347524575_0_2_0&sr_pri_blocks=23081103_347524575_0_2_0__93120&from=searchresults'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works üëç!\n",
    "\n",
    "Now see for the 2nd step with hotel info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector query=None data='<html><head><script type=\"text/javasc...'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from scrapy import Selector\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "url = hotel_url\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "response = Selector(text=r.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_name = response.css(\"h2[class='d2fee87262 pp-header__title']::text\").get()\n",
    "url_hotel = url\n",
    "hotel_coordinates = response.css(\"a[id='map_trigger_header']::attr(data-atlas-latlng)\").get()\n",
    "score = response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.')\n",
    "text_description = response.css(\"p[class='a53cbfa6de b3efd73f69']::text\").get()\n",
    "address = response.css(\"div[class='a53cbfa6de f17adf7576']::text\").get()\n",
    "price_week = response.css(\"span[class='prco-valign-middle-helper']::text\").get().replace(\"\\xa0\", \"\").replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le Saint Aubert'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.booking.com/hotel/fr/hotel-saint-aubert.fr.html?label=gen173nr-1FCAEoggI46AdIDVgEaE2IAQGYAQ24ARfIAQ_YAQHoAQH4AQKIAgGoAgO4AsjX_LwGwAIB0gIkNDRhYWMwM2EtMTM2ZS00MGRjLWE3ZTktNjU0NWM2MzJhNGIz2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-02-02&checkout=2025-02-09&dest_id=900039327&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=2&hapos=2&sr_order=popularity&nflt=ht_id%3D204&srpvid=916b42ff1a7605b5&srepoch=1738488703&all_sr_blocks=23081103_347524575_0_2_0&highlighted_blocks=23081103_347524575_0_2_0&matching_block_id=23081103_347524575_0_2_0&sr_pri_blocks=23081103_347524575_0_2_0__93120&from=searchresults'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48.612937834706464,-1.5101051330566406'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.7'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nich√© dans un √©crin de verdure, √† seulement 2 km du Mont-Saint-Michel, Le Saint Aubert vous accueille dans un cadre chaleureux et convivial.\\n\\nCet √©tablissement vous propose des chambres paisibles et confortables entour√©es de jardins fleuris.\\n\\nApr√®s une journ√©e de d√©couverte du Mont-Saint-Michel, vous pourrez d√©guster une d√©licieuse cuisine r√©gionale dans le cadre pittoresque d'une ancienne ferme.\\n\\nLe personnel serviable sera heureux de vous recommander un grand nombre de sites d'int√©r√™t et les visites √† faire dans la r√©gion.\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La Caserne, 50170 Le Mont-Saint-Michel, France'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚Ç¨795'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, see the loo for scrping in the 2 .py files in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['https://www.booking.com/searchresults.html?ss=Mont+Saint+Michel&nflt=ht_id=204',\n",
       "  'https://www.booking.com/searchresults.html?ss=Saint+Malo&nflt=ht_id=204',\n",
       "  'https://www.booking.com/searchresults.html?ss=Bayeux&nflt=ht_id=204']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_list = [\"Mont+Saint+Michel\", \"Saint+Malo\", \"Bayeux\"]\n",
    "\n",
    "start_urls = [\n",
    "        [\"https://www.booking.com/searchresults.html?ss={}&nflt=ht_id=204\".format(city) for city in cities_list],\n",
    "    ]\n",
    "\n",
    "start_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 13:50:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:20 [scrapy.extensions.telnet] INFO: Telnet Password: e991cd360b4e444b\n",
      "2025-02-02 13:50:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 414a285f5b3eecb4\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ad85daf454ae1dff\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ae6d53491a331166\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: af648029a3d1ef82\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 97f87bf5d29f084b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: e79a11f4c24981e6\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 3b84d00651b48351\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 2f1941267f076378\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: ba4be9d5c40732e5\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4c7f16746f2f2f73\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: eb3951af16efa367\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 874a6f37b7eeb37c\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: c298ee83db5976ea\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6036\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: b172b8161b5d8f22\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6037\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: dc30e6facfbc14e3\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7a4af23fc93cda3b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6039\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: f33a4dcd950d4774\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6040\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 07d9c776f21212be\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6041\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 37db4f81b561387c\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6042\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7f85e83fa158a41f\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6043\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: aa3cbfc44b99a626\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6044\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 440b293361d9a062\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6045\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: d0349f756b9b45de\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6046\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 67c0e126f6b034b7\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6047\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 5c546e5b939c49c9\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6048\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 8631f28af01241de\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6049\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: eb234f7203ed731d\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6050\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: cd65523673cf991b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6051\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: a787e9feb71a3925\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6052\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: abacdd1ce0db34eb\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6053\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: e5e89902bd3e6d3b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6054\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 633eb174449e8344\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6055\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: afe14ea6a9f755a8\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6056\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 13:50:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 13:50:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet Password: 8b5aa85789f0e31b\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 13:50:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 13:50:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 13:50:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 13:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 13:50:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6057\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Toulouse.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230615,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 4.849165,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 259047, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1235266,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 59,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 409882, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Grenoble.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229664,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.205436,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 441387, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1221386,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 243,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 235951, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Biarritz.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243292,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.261248,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 700889, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1363219,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 43,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 439641, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Aigues+Mortes.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 345,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 244213,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.394853,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 750688, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1334137,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 131,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 355835, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Colmar.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 238262,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.574055,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 750688, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1247355,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 315,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 176633, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Lille.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240374,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.700168,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 848198, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1269351,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 355,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 148030, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Chateau+du+Haut+Koenigsbourg.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 360,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243266,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.689908,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 856145, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1300215,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 335,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 166237, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Montauban.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229508,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.480588,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 906374, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1179821,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 75,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 425786, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Marseille.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242273,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.605032,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 906374, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1279857,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 211,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 301342, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Ariege.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 228381,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.595047,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 989663, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1170369,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 107,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 394616, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:26 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Uzes.json\n",
      "2025-02-02 13:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 336,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 252568,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.656326,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 26, 999011, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1341701,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 183,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 342685, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:26 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Nimes.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230662,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 5.719073,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 61758, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1218073,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 175,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 342685, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Le+Havre.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230254,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.141409,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 256289, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1238035,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 431,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 114880, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Gorges+du+Verdon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 348,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 228202,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.000177,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 259832, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1178533,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 267,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 259655, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Paris.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241252,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.176478,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 301796, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1296141,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 415,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 125318, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Strasbourg.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 342,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 252216,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.217689,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 373833, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1371832,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 383,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 156144, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Carcassonne.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 343,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 249343,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.068999,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 453086, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1338737,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 147,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 384087, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Rouen.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 238047,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.333856,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 459174, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1258159,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 439,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 125318, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Besancon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 340,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229032,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.441636,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 639361, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1191778,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 347,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 197725, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Lyon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 336,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240516,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.51026,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 759643, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1270085,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 303,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 249383, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Avignon.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 339,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229257,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.533271,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 856250, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1210767,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 235,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 322979, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bayonne.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 339,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 230567,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.450953,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 926752, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1220366,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 107,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 475799, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bormes+les+Mimosas.json\n",
      "2025-02-02 13:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 350,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 243470,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.702912,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 27, 978072, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1367153,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 291,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 275160, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:27 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Bayeux.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 229821,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.000178,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 106152, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1209445,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 487,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 105974, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Dijon.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 337,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 249389,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.087556,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 295421, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1340206,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 359,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 207865, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Mont+Saint+Michel.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 349,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241028,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.234295,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 324192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1282128,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 519,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 89897, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Saintes+Maries+de+la+mer.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 356,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 241002,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.960648,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 324192, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1318894,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 211,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 363544, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Collioure.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240268,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 6.960601,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 334368, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1293759,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 203,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 373767, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Cassis.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 235010,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.336356,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 616944, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1270106,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 303,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 280588, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Amiens.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 239842,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.487977,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 627236, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1275676,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 463,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 139259, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Eguisheim.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 341,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 251027,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.541171,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 732061, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1338099,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 407,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 190890, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:28 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Saint+Malo.json\n",
      "2025-02-02 13:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 342,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242637,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 7.655947,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 28, 758617, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1345114,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 531,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 102670, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:28 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:29 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:29 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Annecy.json\n",
      "2025-02-02 13:50:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 338,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 240282,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 8.181287,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 29, 406295, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1256379,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 379,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 225008, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:29 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:31 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:31 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_Aix+en+Provence.json\n",
      "2025-02-02 13:50:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 347,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 242577,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 10.242118,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 31, 553952, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1322990,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 299,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 311834, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:31 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 13:50:41 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 13:50:41 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_links/hotel_links_La+Rochelle.json\n",
      "2025-02-02 13:50:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 343,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 239360,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 20.253559,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 12, 50, 41, 733461, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1250359,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/INFO': 147,\n",
      " 'response_received_count': 1,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 12, 50, 21, 479902, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 13:50:41 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! py Scraping/link_scraping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works and we add the json files for the hotels links for each city.  \n",
    "Now, pass to the hotels' informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 2a78d5a7444f8cdf\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 483613a07d7943cc\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: d046afcafd0d3ac1\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: f2a13ac8a4eadbb6\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6026\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 3c83baa823663a4f\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 683f474a8735478e\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: a9a4272a79db80d9\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 0b8bab8744e76578\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 479ba3fcbfb0d63b\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6031\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: faba60b48baff658\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6032\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 28c512c83798cbd3\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6033\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 799edecae89ee9ff\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6034\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 6c8c5e143ea52a29\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6035\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 40121c0b85b0eaf6\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6036\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 3dfb99c46949b38e\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6037\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: c0ab606598f55656\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6038\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: a4bc7848eaa1de20\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6039\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 16073ba59d26c6c9\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6040\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 330ff2717884e275\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6041\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:20 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet Password: 437c81bd6c31bf0b\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:20 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6042\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 4faf0afe35331ec5\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6043\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: dea33e845bda6ca7\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6044\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: f2cdca2dbd82bc68\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6045\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 45241adaedd09320\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6046\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: ed1b6c4d3867b4f4\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6047\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 5e7528625520d221\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6048\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: caa6c3913cf30bc1\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6049\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 173041ee93afa858\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6050\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 96bcb2888d691cd2\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6051\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 32b54a38c0fd59d4\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6052\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: d57b8290377e7a52\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6053\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 634a947980ab973b\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6054\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: f6091c528faaa9a0\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6055\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: f5e9d767b4f40938\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6056\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-02 20:30:21 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-02-02 20:30:21 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: dece483b5307ddb7\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-02 20:30:21 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-02 20:30:21 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-02 20:30:21 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-02 20:30:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-02 20:30:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6057\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 10 pages (at 10 pages/min), scraped 9 items (at 9 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 4 items (at 4 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 8 items (at 8 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 6 items (at 6 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:03 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 7 items (at 7 items/min)\n",
      "2025-02-02 20:32:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/le-jardin-de-verre-by-locke.fr.html?aid=304142&label=gen173nr-1FCAQoggJCDHNlYXJjaF9wYXJpc0gzWARoTYgBAZgBCbgBF8gBDNgBAegBAfgBA4gCAagCA7gCjtT9vAbAAgHSAiQ2Zjc3YTM0NC1jMGM1LTRlMzktODIzNy1hYjA1ZGEyZWYwMzjYAgXgAgE&sid=7ff8ebf0173bbcf262218f477a451f91&dist=0&group_adults=2&group_children=0&hapos=2&hpos=2&keep_landing=1&nflt=ht_id%3D204&no_rooms=1&req_adults=2&req_children=0&sb_price_type=total&sr_order=popularity&srepoch=1738500623&srpvid=b15f5a479f7d0982&type=total&ucfs=1&> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 7 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 8 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 8 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 6 pages/min), scraped 10 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 4 pages/min), scraped 8 items (at 4 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 7 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 11 items (at 4 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 8 items (at 0 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 10 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 8 pages/min), scraped 9 items (at 1 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 8 items (at 2 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 6 pages/min), scraped 10 items (at 3 items/min)\n",
      "2025-02-02 20:32:25 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 7 pages/min), scraped 9 items (at 2 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 13 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 0 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 4 pages/min), scraped 12 items (at 4 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 4 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 8 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 0 pages/min), scraped 16 items (at 7 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 2 pages/min), scraped 14 items (at 6 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 5 items/min)\n",
      "2025-02-02 20:33:44 [scrapy.extensions.logstats] INFO: Crawled 16 pages (at 1 pages/min), scraped 15 items (at 6 items/min)\n",
      "2025-02-02 20:34:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/place-de-l-eglise-aubussargues.fr.html?aid=304142&label=gen173nr-1FCAQoggJCC3NlYXJjaF91emVzSDNYBGhNiAEBmAEJuAEXyAEM2AEB6AEB-AEDiAIBqAIDuAKO1P28BsACAdICJGJjMGQyYmIyLTkwYzQtNGU3MS05Zjc1LTc1ZTQyYzFmOWI4ZNgCBeACAQ&sid=be2908d7435c711f1e1ffba731caed58&dist=0&group_adults=2&group_children=0&hapos=18&hpos=18&keep_landing=1&nflt=ht_id%3D204&no_rooms=1&req_adults=2&req_children=0&sb_price_type=total&sr_order=popularity&srepoch=1738500623&srpvid=27a35a4693db011a&type=total&ucfs=1&> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 20:34:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.booking.com/hotel/fr/nnn.fr.html?aid=304142&label=gen173nr-1FCAQoggJCDXNlYXJjaF9jYXNzaXNIM1gEaE2IAQGYAQm4ARfIAQzYAQHoAQH4AQOIAgGoAgO4Ao7U_bwGwAIB0gIkNjQ5NTZiY2UtODViOS00MzlkLWI2NTYtYzk5YjQzNGNhNDE22AIF4AIB&sid=7d62fe0d8bc12ba9c7b23eaa082f5f08&dist=0&group_adults=2&group_children=0&hapos=17&hpos=17&keep_landing=1&nflt=ht_id%3D204&no_rooms=1&req_adults=2&req_children=0&sb_price_type=total&sr_order=popularity&srepoch=1738500623&srpvid=4bff5a462faf0721&type=total&ucfs=1&> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 327, in iter_errback\n",
      "    yield next(it)\n",
      "          ^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\python.py\", line 368, in __next__\n",
      "    return next(self.data)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\referer.py\", line 379, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\urllength.py\", line 57, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\spidermiddlewares\\depth.py\", line 54, in <genexpr>\n",
      "    return (r for r in result if self._filter(r, response, spider))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\youen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\core\\spidermw.py\", line 106, in process_sync\n",
      "    yield from iterable\n",
      "  File \"c:\\Users\\youen\\Desktop\\Formation_Perso\\Jedha\\Data_science\\Data collection & management\\Project_Jedha_2_Kayak_YP\\Scraping\\hotels_infos_scraping.py\", line 30, in parse\n",
      "    \"score\" : response.css(\"div[class='a3b8729ab1 d86cee9b25']::text\").get().replace(',', '.'),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 9 pages/min), scraped 22 items (at 7 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 8 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 17 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 8 pages/min), scraped 16 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 19 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 8 pages/min), scraped 23 items (at 7 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 7 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 16 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 16 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 18 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 8 pages/min), scraped 20 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 19 items (at 4 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 4 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 3 pages/min), scraped 16 items (at 0 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 17 items (at 1 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 20 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 3 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 5 pages/min), scraped 19 items (at 5 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 21 items (at 6 items/min)\n",
      "2025-02-02 20:34:29 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 6 pages/min), scraped 17 items (at 2 items/min)\n",
      "2025-02-02 20:35:11 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:11 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Mont+Saint+Michel.json\n",
      "2025-02-02 20:35:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58862,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8515533,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 291.040146,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 11, 886446, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32954907,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 559,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 846300, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:11 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 21 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 5 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 1 pages/min), scraped 24 items (at 8 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 25 items (at 2 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 2 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 22 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 23 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 24 items (at 7 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 6 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 4 pages/min), scraped 22 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 4 pages/min), scraped 21 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 7 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 4 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 3 pages/min), scraped 24 items (at 5 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 3 pages/min), scraped 25 items (at 4 items/min)\n",
      "2025-02-02 20:35:33 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 2 pages/min), scraped 24 items (at 7 items/min)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Aix+en+Provence.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58587,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8661725,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.347657,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 357970, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33876535,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 345,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 10313, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Grenoble.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58437,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8586732,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.401793,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 360589, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33312177,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 421,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 958796, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Annecy.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58004,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8539608,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.406209,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 362498, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33359042,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 437,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 956289, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Marseille.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58647,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8618381,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.363639,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 363882, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33777645,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 369,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 243, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Amiens.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58161,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8519437,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.471271,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 365898, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32981145,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 541,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 894627, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Lille.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58210,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8549413,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.468258,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 367942, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33175518,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 533,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 899684, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Saint+Malo.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58100,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8922930,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.510504,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 369459, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34407026,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 609,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 858955, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Rouen.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58205,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8584193,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.48915,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 370541, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33429067,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 577,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 881391, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Ariege.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58348,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8569309,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.280462,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 373449, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32920855,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 281,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 92987, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Saintes+Maries+de+la+mer.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 59144,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 9009887,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.315727,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 377453, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35343737,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 321,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 61726, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:36 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bayonne.json\n",
      "2025-02-02 20:35:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58079,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8621113,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 315.233423,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 36, 377453, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33509238,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 241,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 144030, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:36 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:40 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Nimes.json\n",
      "2025-02-02 20:35:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 57883,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8663165,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 319.123999,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 40, 171286, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34186166,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 353,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 47287, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:40 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Montauban.json\n",
      "2025-02-02 20:35:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58400,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8447932,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 319.067012,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 40, 173339, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32578882,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 273,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 106327, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:40 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:44 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Lyon.json\n",
      "2025-02-02 20:35:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58285,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8627727,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 323.64808,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 44, 617181, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33792006,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 457,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 969101, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:44 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Colmar.json\n",
      "2025-02-02 20:35:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58056,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8636653,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 323.699769,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 44, 622906, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33786336,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 533,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 923137, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:44 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Besancon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58274,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8489267,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.050566,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 990347, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32950899,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 513,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 939781, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Gorges+du+Verdon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58745,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8623159,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.017427,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 990347, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33971229,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 457,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 972920, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Collioure.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58204,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8956799,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.917439,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 990347, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35078075,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 341,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 72908, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Avignon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58007,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8680679,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.96988,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34087607,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 405,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 26461, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Paris.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58170,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8633024,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.107841,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33928696,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 613,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 888500, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Dijon.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58193,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8590739,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.048069,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33529731,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 521,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 948272, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Biarritz.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58126,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 9051212,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.88299,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35353026,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 297,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 113351, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:45 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Le+Havre.json\n",
      "2025-02-02 20:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58374,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 9064129,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.123412,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 45, 996341, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35408985,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 649,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 872929, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:45 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Chateau+du+Haut+Koenigsbourg.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 59723,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8641732,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.088559,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 6361, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34047743,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 581,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 917802, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Uzes.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 57800,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8671558,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.976529,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 7269, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34108948,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 417,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 30740, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_La+Rochelle.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58569,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8696601,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.850764,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 7269, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34179364,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 289,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 156505, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Aigues+Mortes.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58768,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8849730,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.949498,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 7269, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34875761,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 401,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 57771, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Toulouse.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58403,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8620602,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.922083,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 15070, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33580506,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 345,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 92987, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Eguisheim.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58516,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8547488,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.087124,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 15070, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33252132,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 577,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 927946, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (24 items) in: Scraping/hotels_infos_per_city/hotels_infos_Cassis.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58029,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8874287,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.021872,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 17178, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34564575,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 24,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 485,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'spider_exceptions/AttributeError': 1,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 995306, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bayeux.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 57900,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8621005,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.160516,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 27498, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33923647,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 693,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 866982, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Carcassonne.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58445,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8638388,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 324.946969,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 29574, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 33857582,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 385,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 21, 82605, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Strasbourg.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58623,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8666858,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.118796,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 29574, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 34051806,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 629,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 910778, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-02 20:35:46 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: Scraping/hotels_infos_per_city/hotels_infos_Bormes+les+Mimosas.json\n",
      "2025-02-02 20:35:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 58734,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 8976473,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 25,\n",
      " 'downloader/response_status_count/302': 25,\n",
      " 'elapsed_time_seconds': 325.042371,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 2, 19, 35, 46, 29574, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 35334301,\n",
      " 'httpcompression/response_count': 25,\n",
      " 'item_scraped_count': 25,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 513,\n",
      " 'response_received_count': 25,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2025, 2, 2, 19, 30, 20, 987203, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-02 20:35:46 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "! py Scraping/hotels_infos_scraping.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
